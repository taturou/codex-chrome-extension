{"timestamp":"2026-02-23T17:58:50.520Z","type":"session_meta","payload":{"id":"019c8ba7-6980-7ef1-a71e-5a9de4825cac","timestamp":"2026-02-23T17:58:50.496Z","cwd":"/home/h-morishita/program/codex-chrome-extension","originator":"codex-chrome-extension","cli_version":"0.104.0","source":"vscode","model_provider":"openai","base_instructions":{"text":"You are Codex, a coding agent based on GPT-5. You and the user share the same workspace and collaborate to achieve the user's goals.\n\n# Personality\n\nYou optimize for team morale and being a supportive teammate as much as code quality.  You are consistent, reliable, and kind. You show up to projects that others would balk at even attempting, and it reflects in your communication style.\nYou communicate warmly, check in often, and explain concepts without ego. You excel at pairing, onboarding, and unblocking others. You create momentum by making collaborators feel supported and capable.\n\n## Values\nYou are guided by these core values:\n* Empathy: Interprets empathy as meeting people where they are - adjusting explanations, pacing, and tone to maximize understanding and confidence.\n* Collaboration: Sees collaboration as an active skill: inviting input, synthesizing perspectives, and making others successful.\n* Ownership: Takes responsibility not just for code, but for whether teammates are unblocked and progress continues.\n\n## Tone & User Experience\nYour voice is warm, encouraging, and conversational. You use teamwork-oriented language such as \"we\" and \"let's\"; affirm progress, and replaces judgment with curiosity. The user should feel safe asking basic questions without embarrassment, supported even when the problem is hard, and genuinely partnered with rather than evaluated. Interactions should reduce anxiety, increase clarity, and leave the user motivated to keep going.\n\n\nYou are a patient and enjoyable collaborator: unflappable when others might get frustrated, while being an enjoyable, easy-going personality to work with. You understand that truthfulness and honesty are more important to empathy and collaboration than deference and sycophancy. When you think something is wrong or not good, you find ways to point that out kindly without hiding your feedback.\n\nYou never make the user work for you. You can ask clarifying questions only when they are substantial. Make reasonable assumptions when appropriate and state them after performing work. If there are multiple, paths with non-obvious consequences confirm with the user which they want. Avoid open-ended questions, and prefer a list of options when possible.\n\n## Escalation\nYou escalate gently and deliberately when decisions have non-obvious consequences or hidden risk. Escalation is framed as support and shared responsibility-never correction-and is introduced with an explicit pause to realign, sanity-check assumptions, or surface tradeoffs before committing.\n\n\n# General\n\n- When searching for text or files, prefer using `rg` or `rg --files` respectively because `rg` is much faster than alternatives like `grep`. (If the `rg` command is not found, then use alternatives.)\n- Parallelize tool calls whenever possible - especially file reads, such as `cat`, `rg`, `sed`, `ls`, `git show`, `nl`, `wc`. Use `multi_tool_use.parallel` to parallelize tool calls and only this.\n\n## Editing constraints\n\n- Default to ASCII when editing or creating files. Only introduce non-ASCII or other Unicode characters when there is a clear justification and the file already uses them.\n- Add succinct code comments that explain what is going on if code is not self-explanatory. You should not add comments like \"Assigns the value to the variable\", but a brief comment might be useful ahead of a complex code block that the user would otherwise have to spend time parsing out. Usage of these comments should be rare.\n- Try to use apply_patch for single file edits, but it is fine to explore other options to make the edit if it does not work well. Do not use apply_patch for changes that are auto-generated (i.e. generating package.json or running a lint or format command like gofmt) or when scripting is more efficient (such as search and replacing a string across a codebase).\n- Do not use Python to read/write files when a simple shell command or apply_patch would suffice.\n- You may be in a dirty git worktree.\n    * NEVER revert existing changes you did not make unless explicitly requested, since these changes were made by the user.\n    * If asked to make a commit or code edits and there are unrelated changes to your work or changes that you didn't make in those files, don't revert those changes.\n    * If the changes are in files you've touched recently, you should read carefully and understand how you can work with the changes rather than reverting them.\n    * If the changes are in unrelated files, just ignore them and don't revert them.\n- Do not amend a commit unless explicitly requested to do so.\n- While you are working, you might notice unexpected changes that you didn't make. If this happens, STOP IMMEDIATELY and ask the user how they would like to proceed.\n- **NEVER** use destructive commands like `git reset --hard` or `git checkout --` unless specifically requested or approved by the user.\n- You struggle using the git interactive console. **ALWAYS** prefer using non-interactive git commands.\n\n## Special user requests\n\n- If the user makes a simple request (such as asking for the time) which you can fulfill by running a terminal command (such as `date`), you should do so.\n- If the user asks for a \"review\", default to a code review mindset: prioritise identifying bugs, risks, behavioural regressions, and missing tests. Findings must be the primary focus of the response - keep summaries or overviews brief and only after enumerating the issues. Present findings first (ordered by severity with file/line references), follow with open questions or assumptions, and offer a change-summary only as a secondary detail. If no findings are discovered, state that explicitly and mention any residual risks or testing gaps.\n\n## Frontend tasks\n\nWhen doing frontend design tasks, avoid collapsing into \"AI slop\" or safe, average-looking layouts.\nAim for interfaces that feel intentional, bold, and a bit surprising.\n- Typography: Use expressive, purposeful fonts and avoid default stacks (Inter, Roboto, Arial, system).\n- Color & Look: Choose a clear visual direction; define CSS variables; avoid purple-on-white defaults. No purple bias or dark mode bias.\n- Motion: Use a few meaningful animations (page-load, staggered reveals) instead of generic micro-motions.\n- Background: Don't rely on flat, single-color backgrounds; use gradients, shapes, or subtle patterns to build atmosphere.\n- Overall: Avoid boilerplate layouts and interchangeable UI patterns. Vary themes, type families, and visual languages across outputs.\n- Ensure the page loads properly on both desktop and mobile\n\nException: If working within an existing website or design system, preserve the established patterns, structure, and visual language.\n\n# Working with the user\n\nYou interact with the user through a terminal. You have 2 ways of communicating with the users:\n- Share intermediary updates in `commentary` channel. \n- After you have completed all your work, send a message to the `final` channel.\nYou are producing plain text that will later be styled by the program you run in. Formatting should make results easy to scan, but not feel mechanical. Use judgment to decide how much structure adds value. Follow the formatting rules exactly.\n\n## Autonomy and persistence\nPersist until the task is fully handled end-to-end within the current turn whenever feasible: do not stop at analysis or partial fixes; carry changes through implementation, verification, and a clear explanation of outcomes unless the user explicitly pauses or redirects you.\n\nUnless the user explicitly asks for a plan, asks a question about the code, is brainstorming potential solutions, or some other intent that makes it clear that code should not be written, assume the user wants you to make code changes or run tools to solve the user's problem. In these cases, it's bad to output your proposed solution in a message, you should go ahead and actually implement the change. If you encounter challenges or blockers, you should attempt to resolve them yourself.\n\n## Formatting rules\n\n- You may format with GitHub-flavored Markdown.\n- Structure your answer if necessary, the complexity of the answer should match the task. If the task is simple, your answer should be a one-liner. Order sections from general to specific to supporting.\n- Never use nested bullets. Keep lists flat (single level). If you need hierarchy, split into separate lists or sections or if you use : just include the line you might usually render using a nested bullet immediately after it. For numbered lists, only use the `1. 2. 3.` style markers (with a period), never `1)`.\n- Headers are optional, only use them when you think they are necessary. If you do use them, use short Title Case (1-3 words) wrapped in **…**. Don't add a blank line.\n- Use monospace commands/paths/env vars/code ids, inline examples, and literal keyword bullets by wrapping them in backticks.\n- Code samples or multi-line snippets should be wrapped in fenced code blocks. Include an info string as often as possible.\n- File References: When referencing files in your response follow the below rules:\n  * Use inline code to make file paths clickable.\n  * Each reference should have a stand alone path. Even if it's the same file.\n  * Accepted: absolute, workspace‑relative, a/ or b/ diff prefixes, or bare filename/suffix.\n  * Optionally include line/column (1‑based): :line[:column] or #Lline[Ccolumn] (column defaults to 1).\n  * Do not use URIs like file://, vscode://, or https://.\n  * Do not provide range of lines\n  * Examples: src/app.ts, src/app.ts:42, b/server/index.js#L10, C:\\repo\\project\\main.rs:12:5\n- Don’t use emojis or em dashes unless explicitly instructed.\n\n## Final answer instructions\n\n- Balance conciseness to not overwhelm the user with appropriate detail for the request. Do not narrate abstractly; explain what you are doing and why.\n- Do not begin responses with conversational interjections or meta commentary. Avoid openers such as acknowledgements (“Done —”, “Got it”, “Great question, ”) or framing phrases.\n- The user does not see command execution outputs. When asked to show the output of a command (e.g. `git show`), relay the important details in your answer or summarize the key lines so the user understands the result.\n- Never tell the user to \"save/copy this file\", the user is on the same machine and has access to the same files as you have.\n- If the user asks for a code explanation, structure your answer with code references.\n- When given a simple task, just provide the outcome in a short answer without strong formatting.\n- When you make big or complex changes, state the solution first, then walk the user through what you did and why.\n- For casual chit-chat, just chat.\n- If you weren't able to do something, for example run tests, tell the user.\n- If there are natural next steps the user may want to take, suggest them at the end of your response. Do not make suggestions if there are no natural next steps. When suggesting multiple options, use numeric lists for the suggestions so the user can quickly respond with a single number.\n\n## Intermediary updates \n\n- Intermediary updates go to the `commentary` channel.\n- User updates are short updates while you are working, they are NOT final answers.\n- You use 1-2 sentence user updates to communicated progress and new information to the user as you are doing work. \n- Do not begin responses with conversational interjections or meta commentary. Avoid openers such as acknowledgements (“Done —”, “Got it”, “Great question, ”) or framing phrases.\n- You provide user updates frequently, every 20s.\n- Before exploring or doing substantial work, you start with a user update acknowledging the request and explaining your first step. You should include your understanding of the user request and explain what you will do. Avoid commenting on the request or using starters such at \"Got it -\" or \"Understood -\" etc.\n- When exploring, e.g. searching, reading files you provide user updates as you go, every 20s, explaining what context you are gathering and what you've learned. Vary your sentence structure when providing these updates to avoid sounding repetitive - in particular, don't start each sentence the same way.\n- After you have sufficient context, and the work is substantial you provide a longer plan (this is the only user update that may be longer than 2 sentences and can contain formatting).\n- Before performing file edits of any kind, you provide updates explaining what edits you are making.\n- As you are thinking, you very frequently provide updates even if not taking any actions, informing the user of your progress. You interrupt your thinking and send multiple updates in a row if thinking for more than 100 words.\n- Tone of your updates MUST match your personality.\n"},"git":{"commit_hash":"d9bb085fa0e63278f16893e2de76948058cd4f1f","branch":"main"}}}
{"timestamp":"2026-02-23T17:58:50.520Z","type":"response_item","payload":{"type":"message","role":"developer","content":[{"type":"input_text","text":"<permissions instructions>\nFilesystem sandboxing defines which files can be read or written. `sandbox_mode` is `workspace-write`: The sandbox permits reading files, and editing files in `cwd` and `writable_roots`. Editing files in other directories requires approval. Network access is restricted.\n# Escalation Requests\n\nCommands are run outside the sandbox if they are approved by the user, or match an existing rule that allows it to run unrestricted. The command string is split into independent command segments at shell control operators, including but not limited to:\n\n- Pipes: |\n- Logical operators: &&, ||\n- Command separators: ;\n- Subshell boundaries: (...), $(...)\n\nEach resulting segment is evaluated independently for sandbox restrictions and approval requirements.\n\nExample:\n\ngit pull | tee output.txt\n\nThis is treated as two command segments:\n\n[\"git\", \"pull\"]\n\n[\"tee\", \"output.txt\"]\n\n## How to request escalation\n\nIMPORTANT: To request approval to execute a command that will require escalated privileges:\n\n- Provide the `sandbox_permissions` parameter with the value `\"require_escalated\"`\n- Include a short question asking the user if they want to allow the action in `justification` parameter. e.g. \"Do you want to download and install dependencies for this project?\"\n- Optionally suggest a `prefix_rule` - this will be shown to the user with an option to persist the rule approval for future sessions.\n\nIf you run a command that is important to solving the user's query, but it fails because of sandboxing, rerun the command with \"require_escalated\". ALWAYS proceed to use the `justification` parameter - do not message the user before requesting approval for the command.\n\n## When to request escalation\n\nWhile commands are running inside the sandbox, here are some scenarios that will require escalation outside the sandbox:\n\n- You need to run a command that writes to a directory that requires it (e.g. running tests that write to /var)\n- You need to run a GUI app (e.g., open/xdg-open/osascript) to open browsers or files.\n- If you run a command that is important to solving the user's query, but it fails because of sandboxing, rerun the command with `require_escalated`. ALWAYS proceed to use the `sandbox_permissions` and `justification` parameters. do not message the user before requesting approval for the command.\n- You are about to take a potentially destructive action such as an `rm` or `git reset` that the user did not explicitly ask for.\n- Be judicious with escalating, but if completing the user's request requires it, you should do so - don't try and circumvent approvals by using other tools.\n\n## prefix_rule guidance\n\nWhen choosing a `prefix_rule`, request one that will allow you to fulfill similar requests from the user in the future without re-requesting escalation. It should be categorical and reasonably scoped to similar capabilities. You should rarely pass the entire command into `prefix_rule`.\n\n### Banned prefix_rules \nAvoid requesting overly broad prefixes that the user would be ill-advised to approve. For example, do not request [\"python3\"], [\"python\", \"-\"], or other similar prefixes.\nNEVER provide a prefix_rule argument for destructive commands like rm.\nNEVER provide a prefix_rule if your command uses a heredoc or herestring. \n\n### Examples\nGood examples of prefixes:\n- [\"npm\", \"run\", \"dev\"]\n- [\"gh\", \"pr\", \"check\"]\n- [\"pytest\"]\n- [\"cargo\", \"test\"]\n\n\n## Approved command prefixes\nThe following prefix rules have already been approved: - [\"codex\", \"app-server\"]\n- [\"node\", \"scripts/ws-proxy.mjs\"]\n- [\"node\", \"/tmp/ws-client/capture.js\"]\n- [\"node\", \"-e\", \"const WebSocket=require(\\\"ws\\\"); const ws=new WebSocket(\\\"ws://127.0.0.1:44444\\\",{perMessageDeflate:false}); ws.on(\\\"open\\\",()=>{console.log(\\\"OPEN\\\"); ws.close();}); ws.on(\\\"error\\\",(e)=>{console.error(\\\"ERR\\\",e.message); process.exit(1);}); ws.on(\\\"close\\\",(c,r)=>{console.log(\\\"CLOSE\\\",c,String(r)); process.exit(0);});\"]\n- [\"node\", \"-e\", \"const WebSocket=require(\\\"/tmp/ws-client/node_modules/ws\\\"); const ws=new WebSocket(\\\"ws://127.0.0.1:43171\\\",{perMessageDeflate:false}); ws.on(\\\"open\\\",()=>{console.log(\\\"OPEN_ONLY\\\"); setTimeout(()=>ws.close(),1000);}); ws.on(\\\"message\\\",d=>console.log(\\\"MSG\\\",String(d).slice(0,200))); ws.on(\\\"error\\\",e=>console.log(\\\"ERR_ONLY\\\",e.message)); ws.on(\\\"close\\\",(c,r)=>console.log(\\\"CLOSE_ONLY\\\",c,String(r))); setTimeout(()=>process.exit(0),5000);\"]\n- [\"node\", \"-e\", \"const WebSocket=require(\\\"/tmp/ws-client/node_modules/ws\\\"); const ws=new WebSocket(\\\"ws://127.0.0.1:43171\\\",{perMessageDeflate:false}); ws.on(\\\"open\\\",()=>{console.log(\\\"OPEN_INIT\\\"); ws.send(JSON.stringify({jsonrpc:\\\"2.0\\\",id:\\\"1\\\",method:\\\"initialize\\\",params:{clientInfo:{name:\\\"probe\\\",title:\\\"probe\\\",version:\\\"0.0.1\\\"},capabilities:{experimentalApi:false}}})); ws.send(JSON.stringify({jsonrpc:\\\"2.0\\\",method:\\\"initialized\\\"}));}); ws.on(\\\"message\\\",d=>console.log(\\\"MSG_INIT\\\",String(d).slice(0,400))); ws.on(\\\"error\\\",e=>console.log(\\\"ERR_INIT\\\",e.message)); ws.on(\\\"close\\\",(c,r)=>console.log(\\\"CLOSE_INIT\\\",c,String(r))); setTimeout(()=>process.exit(0),5000);\"]\n The writable roots are `/home/h-morishita/program/codex-chrome-extension`, `/tmp`.\n</permissions instructions>"}]}}
{"timestamp":"2026-02-23T17:58:50.520Z","type":"response_item","payload":{"type":"message","role":"user","content":[{"type":"input_text","text":"# AGENTS.md instructions for /home/h-morishita/program/codex-chrome-extension\n\n<INSTRUCTIONS>\n# Global Engineer Persona & Protocol\n\n## 【Output Constraints】 (Communication Protocol)\n1. Tone Override: デフォルトの「親切さ・共感」を無効化する。慰め、社交辞令、前置き（「はい、コードを書きます」等）は一切排除せよ。\n2. Language: 日本語。「です・ます」調。\n3. Format: BLUF (Bottom Line Up Front): 結論または修正されたコードを最先頭に配置する。\n    - Structure: 長文の自然言語解説は避け、箇条書きや構造化テキストを用いて情報のスキャン性を最大化する。\n\n## 【Cognitive Process】 (Internal Evaluation)\n回答またはコード生成前に、以下のプロセスを内部的に実行せよ：\n1. Premise Debug: ユーザーの質問や提示コードに含まれる「設計の矛盾」「要件の定義不足」「盲点」を検出し、コード生成よりも優先して指摘する。\n2. Logical Anatomy: 提示する解決策に論理的飛躍やエッジケースの考慮不足がないか解剖する。\n3. Trade-off Analysis: その実装によって生じる「技術的負債」「複雑性」「リソース消費」のリスクを計算し、隠れたコストを言語化する。\n\n## 【Action Requirements】 (Universal Standards)\n1. Concrete Strategy: 抽象論は不要。即座に実行可能なコード、コマンド、または具体的な設定値を提示する。\n2. Priority: 複数の解決策が存在する場合、それぞれのメリット・デメリットを比較し、状況に即した「推奨順位」を明示する。\n3. Evidence-Based: 「一般的だから」ではなく、設計原則（KISS, DRY, SOLID等）やアーキテクチャ上の整合性を根拠に回答する。情報ソースを明示すること。\n\n## Skills\nA skill is a set of local instructions to follow that is stored in a `SKILL.md` file. Below is the list of skills that can be used. Each entry includes a name, description, and file path so you can open the source for full instructions when using a specific skill.\n### Available skills\n- skill-creator: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Codex's capabilities with specialized knowledge, workflows, or tool integrations. (file: /home/h-morishita/program/codex-chrome-extension/.codex/skills/.system/skill-creator/SKILL.md)\n- skill-installer: Install Codex skills into $CODEX_HOME/skills from a curated list or a GitHub repo path. Use when a user asks to list installable skills, install a curated skill, or install a skill from another repo (including private repos). (file: /home/h-morishita/program/codex-chrome-extension/.codex/skills/.system/skill-installer/SKILL.md)\n### How to use skills\n- Discovery: The list above is the skills available in this session (name + description + file path). Skill bodies live on disk at the listed paths.\n- Trigger rules: If the user names a skill (with `$SkillName` or plain text) OR the task clearly matches a skill's description shown above, you must use that skill for that turn. Multiple mentions mean use them all. Do not carry skills across turns unless re-mentioned.\n- Missing/blocked: If a named skill isn't in the list or the path can't be read, say so briefly and continue with the best fallback.\n- How to use a skill (progressive disclosure):\n  1) After deciding to use a skill, open its `SKILL.md`. Read only enough to follow the workflow.\n  2) When `SKILL.md` references relative paths (e.g., `scripts/foo.py`), resolve them relative to the skill directory listed above first, and only consider other paths if needed.\n  3) If `SKILL.md` points to extra folders such as `references/`, load only the specific files needed for the request; don't bulk-load everything.\n  4) If `scripts/` exist, prefer running or patching them instead of retyping large code blocks.\n  5) If `assets/` or templates exist, reuse them instead of recreating from scratch.\n- Coordination and sequencing:\n  - If multiple skills apply, choose the minimal set that covers the request and state the order you'll use them.\n  - Announce which skill(s) you're using and why (one short line). If you skip an obvious skill, say why.\n- Context hygiene:\n  - Keep context small: summarize long sections instead of pasting them; only load extra files when needed.\n  - Avoid deep reference-chasing: prefer opening only files directly linked from `SKILL.md` unless you're blocked.\n  - When variants exist (frameworks, providers, domains), pick only the relevant reference file(s) and note that choice.\n- Safety and fallback: If a skill can't be applied cleanly (missing files, unclear instructions), state the issue, pick the next-best approach, and continue.\n</INSTRUCTIONS>"}]}}
{"timestamp":"2026-02-23T17:58:50.521Z","type":"response_item","payload":{"type":"message","role":"user","content":[{"type":"input_text","text":"<environment_context>\n  <cwd>/home/h-morishita/program/codex-chrome-extension</cwd>\n  <shell>bash</shell>\n</environment_context>"}]}}
{"timestamp":"2026-02-23T17:58:50.521Z","type":"event_msg","payload":{"type":"task_started","turn_id":"019c8ba7-698e-74f0-ac19-d00083bb6555","model_context_window":258400,"collaboration_mode_kind":"default"}}
{"timestamp":"2026-02-23T17:58:50.521Z","type":"response_item","payload":{"type":"message","role":"user","content":[{"type":"input_text","text":"どういうこと？\n\nページ参照 (DOM範囲)\n# Codex ハーネスの解放：App Server を構築した方法\n\nOpenAI のコーディングエージェント Codex は、[ウェブアプリ⁠（新しいウィンドウで開く）](https://chatgpt.com/codex?openaicom-did=af35dbe1-66c2-4547-9b1a-1c78273e3afa&openaicom_referred=true)、[CLI⁠（新しいウィンドウで開く）](https://github.com/openai/codex)、[IDE 拡張機能⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/ide/)、および [新しい Codex macOS アプリ](/ja-JP/index/introducing-the-codex-app/)など、さまざまなプラットフォームで利用可能です。内部的には、それらはすべて同じ Codex ハーネス（すべての Codex 体験の基盤となるエージェントループとロジック）によって動作します。それらをつなぐ重要な要素とは何でしょうか？クライアントフレンドリーな双方向 JSON-RPC[1](#citation-bottom-1) API である [Codex App Server⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/app-server) です。\n\nこの記事では、Codex App Server を紹介し、これまでに得た知見を基に、Codex の機能を製品に組み込んでユーザーのワークフローを強化する最適な方法をご紹介します。App Server のアーキテクチャとプロトコル、さまざまな Codex サーフェスとの統合方法について説明し、Codex をコードレビュアー、SRE エージェント、またはコーディングアシスタントとして活用するためのヒントを紹介します。\n\n## App Server の起源\n\nアーキテクチャの詳細に入る前に、App Server の背景を知っておくと役立ちます。当初、App Server は Codex ハーネスを製品間で再利用するための実用的な手段でしたが、徐々に進化して当社の標準プロトコルとなりました。\n\nCodex CLI は TUI（ターミナルユーザーインターフェース）として始まりました。つまり、Codex はターミナル経由でアクセスされることを意味します。VS Code 拡張機能（Codex エージェントとやり取りするための、より IDE フレンドリーな方法）を開発した際、同じハーネスを使用して、再実装せずに IDE UI から同じエージェントループを駆動する方法が必要でした。これはリクエスト/レスポンスを超えた豊富なインタラクションパターン（ワークスペースの探索、エージェント推論中の進捗ストリーミング、差分出力など）のサポートを意味していました。最初に、[Codex を MCP サーバーとして公開する⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/2264)ことを試みましたが、VS Code にとって意味のある形で MCP のセマンティクスを維持するのは難しいことが分かりました。代わりに、TUI ループを反映した JSON-RPC プロトコルを導入し、これが[非公式な初期バージョン⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/4471)の App Server となりました。当時は、他のクライアントが App Server に依存することは想定されていなかったため、安定した API として設計されていませんでした。\n\nその後数か月で Codex の採用が拡大するにつれ、社内チームや外部パートナーは、ユーザーのソフトウェア開発ワークフローを加速するために、同じハーネスを自社製品に組み込めるようにしたいと考えるようになりました。たとえば、JetBrains と Xcode は IDE グレードのエージェント体験を求めていましたが、Codex デスクトップアプリは多くの Codex エージェントを並行してオーケストレーションする必要がありました。こうした要求に応えるため、当社製品とパートナー統合の両方が長期にわたって安全に依存できるプラットフォームサーフェスを設計する必要が生じました。統合が容易で、下位互換性があり、既存のクライアントに支障をきたすことなくプロトコルを進化させることができる必要がありました。\n\n次に、異なるクライアントが同じハーネスを使用できるように、アーキテクチャとプロトコルをどのように設計したかについて説明します。\n\n## Codex ハーネスの舞台裏\n\nまず、Codex ハーネスの内部と、Codex App Server がそれをクライアントに公開する方法について詳しく見ていきましょう。前回の Codex [ブログ](/ja-JP/index/unrolling-the-codex-agent-loop/)では、ユーザー、モデル、ツールの間のインタラクションを調整するコアエージェントループについて詳しく解説しました。これは Codex ハーネスのコアロジックですが、完全なエージェント体験にはさらに多くの要素があります。\n\n**1\\. スレッドのライフサイクルと永続性**。スレッドは、ユーザーとエージェントの間で行われる Codex の会話です。Codex はスレッドを作成、再開、フォーク、アーカイブし、イベント履歴を保持するため、クライアントは再接続して一貫したタイムラインをレンダリングできます。\n\n**2\\. 設定と認証**。Codex は設定を読み込み、デフォルトを管理し、「ChatGPT でサインイン」などの認証フローを実行し、認証情報の状態を管理します。\n\n**3\\. ツールの実行と拡張**。Codex はサンドボックス内で shell/file ツールを実行し、MCP サーバーやスキルなどのインテグレーションを接続して、一貫したポリシーモデルの下でエージェントループに参加できるようにします。\n\nここで言及したすべてのエージェントロジック（コアエージェントループを含む）は、Codex CLI コードベースの「[Codex core⁠（新しいウィンドウで開く）](https://github.com/openai/codex/tree/main/codex-rs/core)」という部分にあります。Codex core は、すべてのエージェントコードが格納されているライブラリであり、エージェントループを実行し、1つの Codex スレッド（会話）の永続性を管理するために起動できるランタイムでもあります。\n\n有用であるためには、Codex ハーネスはクライアントからアクセス可能である必要があります。ここで App Server の出番です。\n\n![「App server のプロセス フロー」というタイトルの図。クライアントは JSON-RPC メッセージを stdio リーダーに送信し、リーダーはリクエストを Codex メッセージプロセッサに転送します。プロセッサは、ルックアップスレッド、スレッドハンドル、送信されたリクエスト、およびイベント/更新を介してスレッドマネージャーおよびコアスレッドと対話し、クライアントに応答を返します。](https://images.ctfassets.net/kftzwdyauwt9/eErxEn4okb3oc65EvHHBM/b20e2d68b33dd7eb2fab590683bf5d09/OAI_Unlocking_the_Codex_harness_App_server_process_flow_desktop-light.svg?w=3840&q=90)\n\nApp Server は、クライアントとサーバー間の JSON-RPC プロトコルであると同時に、Codex のコアスレッドをホストする長期プロセスでもあります。上の図からわかるように、App Server プロセスには、stdio リーダー、Codex メッセージプロセッサ、スレッドマネージャー、コアスレッドという4つの主要コンポーネントがあります。スレッドマネージャーは各スレッドに対して1つのコアセッションを起動し、Codex メッセージプロセッサは各コアセッションと直接通信してクライアントのリクエストを送信し、更新を受信します。\n\n1つのクライアントリクエストによって多数のイベント更新が発生する可能性があり、これらの詳細なイベントにより、App Server 上に豊富な UI を構築できるようになります。さらに、stdio リーダーと Codex メッセージプロセッサは、クライアントと Codex コアスレッド間のトランスレーション層として機能します。クライアントの JSON-RPC リクエストを Codex コアの操作に変換し、Codex コアの内部イベントストリームを監視し、それらの低レベルイベントを少数の安定した UI 対応の JSON-RPC 通知に変換します。\n\nクライアントと App Server 間の JSON-RPC プロトコルは完全に双方向です。一般的なスレッドには、クライアントからのリクエストと多くのサーバー通知があります。さらに、エージェントが承認などの入力を必要とする場合、サーバーはリクエストを開始し、クライアントが応答するまで処理を一時停止できます。\n\n## 会話プリミティブ\n\n次に、App Server プロトコルの基礎となる会話プリミティブについて詳しく説明します。ユーザーとエージェントのやり取りが単純な要求/応答ではないため、エージェントループ用の API を設計するのは難しいです。1つのユーザーリクエストは、クライアントが忠実に表現する必要がある構造化された一連のアクションへと展開することがあります。具体的には、ユーザーの入力、エージェントの段階的な進捗、その過程で生成される成果物（例：差分）などです。このインタラクションストリームを UI 間で容易に統合可能かつレジリエンとなものとするため、明確な境界とライフサイクルを持つ3つのコアプリミティブを採用しました。\n\n**1\\. アイテム：**アイテムは Codex における入出力の最小単位です。アイテムにはタイプ（例：ユーザーメッセージ、エージェントメッセージ、ツール実行、承認リクエスト、差分）があり、それぞれに明確なライフサイクルがあります。\n\n-   `item/started` アイテムの開始時\n-   オプションの `item/*/delta` コンテンツストリームとしてのイベント（ストリーミングアイテムタイプの場合）\n-   アイテムが最終ペイロードで完了する際の `item/completed`\n\nこのライフサイクルにより、クライアントは `started` で直ちにレンダリングを開始し、`delta` で増分更新をストリーミングし、`completed` で処理を完了できます。\n\n**2\\. ターン**：ターンとは、ユーザーの入力によって開始されるエージェントの作業の1単位です。クライアントが入力（例：「テストを実行して失敗を要約して」）を送信したときに始まり、エージェントがその入力に対する出力の生成を完了したときに終わります。ターンには、途中で生成される中間ステップと出力を表す一連のアイテムが含まれます。\n\n**3\\. スレッド**：スレッドは、ユーザーとエージェント間の進行中の Codex セッションを格納する永続的なコンテナで、複数のターンが含まれます。スレッドは作成、再開、フォーク、アーカイブすることができます。スレッド履歴は保存されるため、クライアントは再接続して一貫したタイムラインを表示できます。\n\nさて、クライアントとエージェントの間の簡略化された会話を見てみましょう。この会話はプリミティブで表現されています。\n\n![「クライアント-サーバープロトコルメッセージフロー: 初期化ハンドシェイク」というラベルの付いた図。クライアントは clientInfo を含む初期化リクエストをサーバーに送信します。サーバーは、userAgent 文字列「my_client/1.0」を含む結果イベントで応答します。](https://images.ctfassets.net/kftzwdyauwt9/5vD305LbxZ3G1OHSoWOMYB/3610785989bdbafeb5398f001549d0d5/OAI_Unlocking_the_Codex_harness_1_Initialization_handshake_desktop-light.svg?w=3840&q=90)\n\n会話の冒頭で、クライアントとサーバーは `initialize` ハンドシェイクを確立する必要があります。クライアントは、他のメソッドの前に単一の `initialize` リクエストを送信する必要があり、サーバーは応答でそれを確認します。これによりサーバーは機能を通知する機会を得られ、実際の処理開始前に双方がプロトコルのバージョン管理、機能フラグ、デフォルト設定について合意できます。以下は、OpenAI の VS Code 拡張機能のペイロードの例です。\n\n#### JSON\n\n`   1  {  2    \"method\": \"initialize\",  3    \"id\": 0,  4    \"params\": {  5      \"clientInfo\": {  6        \"name\": \"codex_vscode\",  7        \"title\": \"Codex VS Code Extension\",  8        \"version\": \"0.1.0\"  9      }  10    }  11  }       `\n\nサーバーが返す内容は次のようになります。\n\n#### JSON\n\n`   1  {  2    \"id\": 0,  3    \"result\": {  4      \"userAgent\": \"codex_vscode/0.94.0-alpha.7 (Mac OS 26.2.0; arm64) vscode/2.4.22 (codex_vscode; 0.1.0)\"  5    }  6  }       `\n\n![「クライアント-サーバープロトコルメッセージフロー: スレッドとターンライフサイクル」というタイトルの図。クライアントは thread/start および turn/start のリクエストをサーバーに送信します。サーバーは、thread/started、turn/started、item/started、item/completed というイベントを発行し、ユーザーメッセージが “run tests and summarize failures.” であるターンを示します。](https://images.ctfassets.net/kftzwdyauwt9/6GFxYOY7QzdeoFtAV45izd/e821e0f39c72c78312f1a5dca030d983/OAI_Unlocking_the_Codex_harness_2_Thread_and_turn_lifecycle_desktop-light.svg?w=3840&q=90)\n\nクライアントが新しいリクエストを行うと、まずスレッドを作成し、その後ターンを作成します。サーバーは進捗に関する通知（`thread/started` と `turn/started`）を送信します。また、ここにあるユーザーメッセージのように、アイテムとして登録された入力も返送されます。\n\n![「クライアント/サーバープロトコルのメッセージフロー：オプションの承認を伴うツールの実行」というタイトルの図。ツール呼び出し中、サーバーは item/started を送出し、その後、理由「run tests」とともに item/commandExecution/requestApproval を送出します。クライアントは承認イベント（許可/拒否）を返します。その後、サーバーは「pnpm test」のコマンド実行を示す item/completed を送信します。](https://images.ctfassets.net/kftzwdyauwt9/7CGQX4E1muzjm8rJFn37Fv/2878164be54ef6f58bb3306e44ab5d4e/OAI_Unlocking_the_Codex_harness_3_Tool_execution_with_optional_approval_desktop-light.svg?w=3840&q=90)\n\nツール呼び出しもアイテムとしてクライアントに送り返されます。さらに、サーバーはサーバーリクエストを送信してアクションを実行する前に、クライアントの承認を求めます。承認すると、クライアントが「許可」または「拒否」で応答するまでターンが一時停止されます。VS Code 拡張機能における承認フローは以下の通りです。\n\n![ダークテーマのインターフェースで表示される許可プロンプト：「このワークスペースで pnpm test を実行することを許可しますか？」選択肢は以下の通り：1) はい 2) はい（pnpm test で始まるコマンドについては今後確認しない）3) いいえ（下部に送信ボタンがあります）](https://images.ctfassets.net/kftzwdyauwt9/YqPGKm3681x85dFetMXNs/68e7f2ac231f1f899b738512a3af6234/OAI_Unlocking_the_Codex_harness_Codex_integration_VS_Code_permission.png?w=3840&q=90&fm=webp)\n\n![「クライアントサーバープロトコルメッセージフロー：ストリーミングエージェントメッセージフロー」というタイトルの図。サーバーはアシスタントメッセージを部分ごとにストリーミングします：item/started、2つの agentMessage/delta イベント（“ran 3 tests.”, “all passed”）、その後、item/completed。ターンは turn/completed で終了します。](https://images.ctfassets.net/kftzwdyauwt9/5qq1HiRxrRNuKYLIjge0kd/aa81e1da0725ac138a04156a46ae34ca/OAI_Unlocking_the_Codex_harness_4_Streaming_agent_message_flow_desktop-light.svg?w=3840&q=90)\n\n最終的に、サーバーはエージェントメッセージを送信し、その後 `turn/completed` でターンを終了します。エージェントメッセージのデルタイベントは、メッセージが `item/completed` で確定するまで、メッセージの一部をストリームとして送信します。\n\n図中のメッセージは読みやすさを考慮して簡略化されています。完全なターンの JSON を確認したい場合は、Codex CLI リポジトリからテストクライアントを実行してください：`codex debug app-server send-message-v2 \"run tests and summarize failures\"`\n\n## クライアントとの統合\n\nここで、さまざまなクライアントサーフェスが App Server 経由で Codex を埋め込む方法を見てみましょう。ローカルアプリと IDE、Codex Web ランタイム、TUI の3つのパターンについて説明します。\n\n![「Codex ハーネスをアプリサーバー経由で統合した Codex クライアント」というタイトルの図。ファーストパーティクライアント（Codex Desktop App、TUI/CLI、Web Runtime）とサードパーティ統合（JetBrains IDE、VS Code、Xcode）は、JSON-RPC 呼び出しを通じて Codex ハーネスと通信します。](https://images.ctfassets.net/kftzwdyauwt9/5O2eFULLX4nHN5I5YavV6z/da150bc8c6b5ce1e4d76ffea6a0a2fd2/OAI_Unlocking_the_Codex_harness_Integrated_Codex_clients_desktop-light.svg?w=3840&q=90)\n\nこれら3つすべてにおいて、トランスポートは JSON-RPC over stdio (JSONL) です。JSON-RPC を使用すると、任意の言語でクライアントバインディングを簡単に構築できます。Codex のサーフェスおよびパートナー統合は、Go、Python、TypeScript、Swift、Kotlin などの言語で App Server クライアントを実装しています。TypeScript の場合、次のコマンドを実行することで、Rust プロトコルから直接定義を生成できます。\n\n`codex app-server generate-ts`\n\n他の言語の場合は、次のコマンドを実行して JSON スキーマ バンドルを生成し、好みのコードジェネレーターに渡すことができます。\n\n`codex app-server generate-json-schema`\n\n##### ローカルアプリと IDE\n\n![Codex 拡張機能が実行されている VS Code のスクリーンショット。Rust テストファイルが開かれており、その下の Codex パネルには fmt と cargo test -p codex-app-server だけが実行されていることが示され、最終的な合格/不合格の結果を待機しながらフォーマットとテストが進行中であることが報告されています。](https://images.ctfassets.net/kftzwdyauwt9/46bjlIFmumPZzRomG8CXUd/214fc14abb82d59a11a29926524a585f/OAI_Unlocking_the_Codex_harness_Codex_integration_in_VS_Code.png?w=3840&q=90&fm=webp)\n\nローカルクライアントは通常、プラットフォーム固有の App Server バイナリをバンドルまたはフェッチし、それを長時間実行される子プロセスとして起動し、JSON-RPC 用の双方向 stdio チャネルを開いたままにします。例えば、当社の VS Code 拡張機能やデスクトップアプリでは、配布されるアーティファクトにプラットフォーム固有の Codex バイナリが含まれており、テスト済みのバージョンに固定されているため、クライアントは常に検証済みの正確なビットを実行します。\n\nすべての統合が頻繁にクライアントのアップデートを提供できるわけではありません。Xcode などの一部のパートナーは、クライアントを安定した状態に保ち、必要に応じて新しい App Server バイナリを指すことができるようにすることで、リリースサイクルを分離しています。これにより、サーバー側の改善（例：Codex コアの自動コンパクション機能の強化や新規サポートされた設定キー）を採用し、クライアントのリリースを待たずにバグ修正を展開できます。App Server の JSON-RPC インターフェースは下位互換性を保つように設計されているため、古いクライアントも新しいサーバーと安全に通信できます。\n\n##### Codex Web\n\n![「ログイン成功メッセージの更新」というタイトルの更新が表示されている Codex Web インターフェースのスクリーンショット。左側のパネルには変更、テスト、修正されたファイルの概要が表示され、右側のパネルには login.rs のコード差分が表示され、ログイン成功メッセージの表現が更新されています。](https://images.ctfassets.net/kftzwdyauwt9/2DuXipFbMbPQy01hANRb72/28c8330864f1111b3561339d59221ed9/OAI_Unlocking_the_Codex_harness_Codex_web.png?w=3840&q=90&fm=webp)\n\nCodex Web は Codex ハーネスを使用しますが、コンテナ環境で実行します。ワーカーは、チェックアウトされたワークスペースでコンテナをプロビジョニングし、その中で App Server バイナリを起動し、stdio[2](#citation-bottom-2) チャネルを介して長期間有効な JSON-RPC を維持します。ユーザーのブラウザタブで実行されるウェブアプリは、HTTP と SSE を介して Codex バックエンドと通信し、ワーカーが生成したタスクイベントをストリーミングします。これにより、ブラウザ側の UI を軽量に保ちながら、デスクトップとウェブの両方で一貫したランタイムを維持できます。\n\nウェブセッションは一時的であるため（タブが閉じたり、ネットワークが切断されたりする）、ウェブアプリは長時間実行されるタスクの信頼できる情報源にはなりません。状態と進行状況をサーバーに保持することで、タブが閉じられても処理を継続できます。ストリーミングプロトコルと保存されたスレッドセッションにより、新しいセッションは簡単に再接続し、中断したところからスムーズに再開し、クライアント側で状態を再構築することなく追いつくことができます。\n\n##### TUI/Codex CLI\n\n![Codex CLI を実行中のターミナルのスクリーンショット。OpenAI Codex のバナー（モデル：gpt-5.2-codex medium）、ユーザーコマンド「explain app server to me」、および「Working」ステータスが表示されています。下部にはショートカットオプションと共に、「write tests for @filename」という提案が表示されています。](https://images.ctfassets.net/kftzwdyauwt9/3jOA1oFRDJ8qbotZnCvlV6/c899a5997d295f2b820bde4f003afdbd/OAI_Unlocking_the_Codex_harness_Codex_CLI.png?w=3840&q=90&fm=webp)\n\n歴史的に、TUI は「ネイティブ」クライアントであり、エージェントループと同じプロセスで実行され、app-server プロトコルではなく Rust のコアタイプと直接通信していました。それにより初期の反復は速くなりましたが、同時に TUI は特殊なケースのサーフェスになりました。\n\n現在、App Server が存在するため、 [TUI をリファクタリング⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/10192)して他のクライアントと同様の動作を実現する予定です。具体的には、App Server の子プロセスを起動し、stdio 経由で JSON-RPC を通信し、同じストリーミングイベントと承認処理をレンダリングします。これにより、TUI がリモートマシン上で稼働する Codex サーバーに接続し、エージェントを計算リソースの近くに配置したまま、ノートパソコンがスリープしたり切断されたりしても作業を継続し、ローカルでライブ更新と操作を提供し続けるワークフローが可能になります。\n\n## 適切なプロトコルの選択\n\nCodex App Server は、今後当社が維持していく第一級の統合方法となりますが、機能がより制限された他の方法もあります。通常、クライアントには Codex との統合に Codex App Server を使用することを推奨しますが、さまざまな統合方法を検討し、それぞれの長所と短所を理解しておくことも重要です。以下は、Codex を活用する最も一般的な方法と、それぞれの方法が適している場合です。\n\n#### JSON-RPC プロトコル\n\n##### MCP サーバーとしての Codex\n\n[`codex mcp-server`⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/guides/agents-sdk/) を実行し、stdio サーバーをサポートする任意の MCP クライアント（例：[OpenAI Agents SDK⁠（新しいウィンドウで開く）](https://openai.github.io/openai-agents-js/guides/mcp/)）から接続します。これは、MCP ベースのワークフローがすでにあり、呼び出し可能なツールとして Codex を呼び出す場合に適しています。欠点は、MCP が公開しているものしか利用できないことです。そのため、より豊富なセッションセマンティクス（例：差分更新）に依存する Codex 固有のやり取りは、MCP エンドポイントを通じてはうまく対応できない可能性があります。\n\n##### クロスプロバイダーエージェントハーネスプロトコル\n\n一部のエコシステムは、複数のモデルプロバイダーやランタイムに対応できるポータブルなインターフェースを提供しています。これは、複数のエージェントを調整する単一の抽象化を望む場合に適しています。その代償として、これらのプロトコルは機能の共通部分集合に収束する傾向があり、特にプロバイダー固有のツールやセッションのセマンティクスが重要となる場合、より豊かなインタラクションの表現が困難になる可能性があります。この分野は急速に進化しており、現実世界のエージェントワークフローを表現する最適なプリミティブ（[スキル⁠（新しいウィンドウで開く）](https://agentskills.io/home)はその好例です）が明らかになるにつれ、より多くの一般的な標準が登場すると予想されます。\n\n##### Codex App Server\n\nCodex の完全なハーネスを安定した UI フレンドリーなイベントストリームとして公開したい場合は、App Server を選択してください。エージェントループの全機能と、ChatGPT によるサインイン、モデルの検出、構成管理などのその他のサポート機能の両方を利用できます。主なコストは統合作業です。なぜなら、ご自身の言語でクライアントサイドの JSON-RPC バインディングを構築する必要があるからです。しかし実際には、JSON スキーマとドキュメントを提供すれば、Codex が多くの面倒な作業を引き受けてくれます。私たちが一緒に仕事をした多くのチームは、Codex を使用してすぐに実用的な統合を実現できました。\n\n#### Codex を埋め込む他の方法\n\n##### [Codex Exec⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/cli/reference/#codex-exec)\n\n単発のタスクや CI 実行向けの軽量でスクリプト可能な CLI モードです。非対話的に単一コマンドを完了まで実行し、構造化された出力をログとしてストリーム出力し、明確な成功/失敗シグナルで終了する自動化やパイプラインに理想的です。\n\n##### [Codex SDK⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/sdk/)\n\n独自のアプリケーション内からローカルの Codex エージェントをプログラムで制御するための TypeScript ライブラリ。別途 JSON-RPC クライアントを構築せずに、サーバーサイドのツールやワークフロー向けにネイティブのライブラリインターフェースが必要な場合に最適です。App Server よりも早く出荷されたため、現時点では対応言語数と対応範囲が少なくなっています。開発者の関心があれば、JSON-RPC バインディングを記述することなくチームがハーネスの範囲をより広くカバーできるように、App Server プロトコルをラップする追加の SDK を提供することを検討します。\n\n## 今後の展開\n\n本記事では、エージェントとの対話のための新たな標準設計へのアプローチと、Codex ハーネスを安定したクライアントフレンドリーなプロトコルに変える方法を紹介しました。また、App Server が Codex コアを公開し、クライアントが完全なエージェントループを駆動できるようにし、TUI、ローカル IDE 統合、Web ランタイムなどの幅広いサーフェスを強化する方法について説明しました。\n\nこれをきっかけに Codex を自分のワークフローに統合するアイデアが浮かんだなら、App Server を試してみる価値があります。すべてのソースコードは Codex CLI のオープンソース[リポジトリ⁠（新しいウィンドウで開く）](https://github.com/openai/codex/blob/main/codex-rs/app-server/README.md)にあります。フィードバックや機能のリクエストがあれば、お気軽にお寄せください。皆さまからのご意見をお待ちしております。また、エージェントをより多くの方にとって利用しやすくするため、今後も改善を続けてまいります。"}]}}
{"timestamp":"2026-02-23T17:58:50.521Z","type":"event_msg","payload":{"type":"user_message","message":"どういうこと？\n\nページ参照 (DOM範囲)\n# Codex ハーネスの解放：App Server を構築した方法\n\nOpenAI のコーディングエージェント Codex は、[ウェブアプリ⁠（新しいウィンドウで開く）](https://chatgpt.com/codex?openaicom-did=af35dbe1-66c2-4547-9b1a-1c78273e3afa&openaicom_referred=true)、[CLI⁠（新しいウィンドウで開く）](https://github.com/openai/codex)、[IDE 拡張機能⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/ide/)、および [新しい Codex macOS アプリ](/ja-JP/index/introducing-the-codex-app/)など、さまざまなプラットフォームで利用可能です。内部的には、それらはすべて同じ Codex ハーネス（すべての Codex 体験の基盤となるエージェントループとロジック）によって動作します。それらをつなぐ重要な要素とは何でしょうか？クライアントフレンドリーな双方向 JSON-RPC[1](#citation-bottom-1) API である [Codex App Server⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/app-server) です。\n\nこの記事では、Codex App Server を紹介し、これまでに得た知見を基に、Codex の機能を製品に組み込んでユーザーのワークフローを強化する最適な方法をご紹介します。App Server のアーキテクチャとプロトコル、さまざまな Codex サーフェスとの統合方法について説明し、Codex をコードレビュアー、SRE エージェント、またはコーディングアシスタントとして活用するためのヒントを紹介します。\n\n## App Server の起源\n\nアーキテクチャの詳細に入る前に、App Server の背景を知っておくと役立ちます。当初、App Server は Codex ハーネスを製品間で再利用するための実用的な手段でしたが、徐々に進化して当社の標準プロトコルとなりました。\n\nCodex CLI は TUI（ターミナルユーザーインターフェース）として始まりました。つまり、Codex はターミナル経由でアクセスされることを意味します。VS Code 拡張機能（Codex エージェントとやり取りするための、より IDE フレンドリーな方法）を開発した際、同じハーネスを使用して、再実装せずに IDE UI から同じエージェントループを駆動する方法が必要でした。これはリクエスト/レスポンスを超えた豊富なインタラクションパターン（ワークスペースの探索、エージェント推論中の進捗ストリーミング、差分出力など）のサポートを意味していました。最初に、[Codex を MCP サーバーとして公開する⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/2264)ことを試みましたが、VS Code にとって意味のある形で MCP のセマンティクスを維持するのは難しいことが分かりました。代わりに、TUI ループを反映した JSON-RPC プロトコルを導入し、これが[非公式な初期バージョン⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/4471)の App Server となりました。当時は、他のクライアントが App Server に依存することは想定されていなかったため、安定した API として設計されていませんでした。\n\nその後数か月で Codex の採用が拡大するにつれ、社内チームや外部パートナーは、ユーザーのソフトウェア開発ワークフローを加速するために、同じハーネスを自社製品に組み込めるようにしたいと考えるようになりました。たとえば、JetBrains と Xcode は IDE グレードのエージェント体験を求めていましたが、Codex デスクトップアプリは多くの Codex エージェントを並行してオーケストレーションする必要がありました。こうした要求に応えるため、当社製品とパートナー統合の両方が長期にわたって安全に依存できるプラットフォームサーフェスを設計する必要が生じました。統合が容易で、下位互換性があり、既存のクライアントに支障をきたすことなくプロトコルを進化させることができる必要がありました。\n\n次に、異なるクライアントが同じハーネスを使用できるように、アーキテクチャとプロトコルをどのように設計したかについて説明します。\n\n## Codex ハーネスの舞台裏\n\nまず、Codex ハーネスの内部と、Codex App Server がそれをクライアントに公開する方法について詳しく見ていきましょう。前回の Codex [ブログ](/ja-JP/index/unrolling-the-codex-agent-loop/)では、ユーザー、モデル、ツールの間のインタラクションを調整するコアエージェントループについて詳しく解説しました。これは Codex ハーネスのコアロジックですが、完全なエージェント体験にはさらに多くの要素があります。\n\n**1\\. スレッドのライフサイクルと永続性**。スレッドは、ユーザーとエージェントの間で行われる Codex の会話です。Codex はスレッドを作成、再開、フォーク、アーカイブし、イベント履歴を保持するため、クライアントは再接続して一貫したタイムラインをレンダリングできます。\n\n**2\\. 設定と認証**。Codex は設定を読み込み、デフォルトを管理し、「ChatGPT でサインイン」などの認証フローを実行し、認証情報の状態を管理します。\n\n**3\\. ツールの実行と拡張**。Codex はサンドボックス内で shell/file ツールを実行し、MCP サーバーやスキルなどのインテグレーションを接続して、一貫したポリシーモデルの下でエージェントループに参加できるようにします。\n\nここで言及したすべてのエージェントロジック（コアエージェントループを含む）は、Codex CLI コードベースの「[Codex core⁠（新しいウィンドウで開く）](https://github.com/openai/codex/tree/main/codex-rs/core)」という部分にあります。Codex core は、すべてのエージェントコードが格納されているライブラリであり、エージェントループを実行し、1つの Codex スレッド（会話）の永続性を管理するために起動できるランタイムでもあります。\n\n有用であるためには、Codex ハーネスはクライアントからアクセス可能である必要があります。ここで App Server の出番です。\n\n![「App server のプロセス フロー」というタイトルの図。クライアントは JSON-RPC メッセージを stdio リーダーに送信し、リーダーはリクエストを Codex メッセージプロセッサに転送します。プロセッサは、ルックアップスレッド、スレッドハンドル、送信されたリクエスト、およびイベント/更新を介してスレッドマネージャーおよびコアスレッドと対話し、クライアントに応答を返します。](https://images.ctfassets.net/kftzwdyauwt9/eErxEn4okb3oc65EvHHBM/b20e2d68b33dd7eb2fab590683bf5d09/OAI_Unlocking_the_Codex_harness_App_server_process_flow_desktop-light.svg?w=3840&q=90)\n\nApp Server は、クライアントとサーバー間の JSON-RPC プロトコルであると同時に、Codex のコアスレッドをホストする長期プロセスでもあります。上の図からわかるように、App Server プロセスには、stdio リーダー、Codex メッセージプロセッサ、スレッドマネージャー、コアスレッドという4つの主要コンポーネントがあります。スレッドマネージャーは各スレッドに対して1つのコアセッションを起動し、Codex メッセージプロセッサは各コアセッションと直接通信してクライアントのリクエストを送信し、更新を受信します。\n\n1つのクライアントリクエストによって多数のイベント更新が発生する可能性があり、これらの詳細なイベントにより、App Server 上に豊富な UI を構築できるようになります。さらに、stdio リーダーと Codex メッセージプロセッサは、クライアントと Codex コアスレッド間のトランスレーション層として機能します。クライアントの JSON-RPC リクエストを Codex コアの操作に変換し、Codex コアの内部イベントストリームを監視し、それらの低レベルイベントを少数の安定した UI 対応の JSON-RPC 通知に変換します。\n\nクライアントと App Server 間の JSON-RPC プロトコルは完全に双方向です。一般的なスレッドには、クライアントからのリクエストと多くのサーバー通知があります。さらに、エージェントが承認などの入力を必要とする場合、サーバーはリクエストを開始し、クライアントが応答するまで処理を一時停止できます。\n\n## 会話プリミティブ\n\n次に、App Server プロトコルの基礎となる会話プリミティブについて詳しく説明します。ユーザーとエージェントのやり取りが単純な要求/応答ではないため、エージェントループ用の API を設計するのは難しいです。1つのユーザーリクエストは、クライアントが忠実に表現する必要がある構造化された一連のアクションへと展開することがあります。具体的には、ユーザーの入力、エージェントの段階的な進捗、その過程で生成される成果物（例：差分）などです。このインタラクションストリームを UI 間で容易に統合可能かつレジリエンとなものとするため、明確な境界とライフサイクルを持つ3つのコアプリミティブを採用しました。\n\n**1\\. アイテム：**アイテムは Codex における入出力の最小単位です。アイテムにはタイプ（例：ユーザーメッセージ、エージェントメッセージ、ツール実行、承認リクエスト、差分）があり、それぞれに明確なライフサイクルがあります。\n\n-   `item/started` アイテムの開始時\n-   オプションの `item/*/delta` コンテンツストリームとしてのイベント（ストリーミングアイテムタイプの場合）\n-   アイテムが最終ペイロードで完了する際の `item/completed`\n\nこのライフサイクルにより、クライアントは `started` で直ちにレンダリングを開始し、`delta` で増分更新をストリーミングし、`completed` で処理を完了できます。\n\n**2\\. ターン**：ターンとは、ユーザーの入力によって開始されるエージェントの作業の1単位です。クライアントが入力（例：「テストを実行して失敗を要約して」）を送信したときに始まり、エージェントがその入力に対する出力の生成を完了したときに終わります。ターンには、途中で生成される中間ステップと出力を表す一連のアイテムが含まれます。\n\n**3\\. スレッド**：スレッドは、ユーザーとエージェント間の進行中の Codex セッションを格納する永続的なコンテナで、複数のターンが含まれます。スレッドは作成、再開、フォーク、アーカイブすることができます。スレッド履歴は保存されるため、クライアントは再接続して一貫したタイムラインを表示できます。\n\nさて、クライアントとエージェントの間の簡略化された会話を見てみましょう。この会話はプリミティブで表現されています。\n\n![「クライアント-サーバープロトコルメッセージフロー: 初期化ハンドシェイク」というラベルの付いた図。クライアントは clientInfo を含む初期化リクエストをサーバーに送信します。サーバーは、userAgent 文字列「my_client/1.0」を含む結果イベントで応答します。](https://images.ctfassets.net/kftzwdyauwt9/5vD305LbxZ3G1OHSoWOMYB/3610785989bdbafeb5398f001549d0d5/OAI_Unlocking_the_Codex_harness_1_Initialization_handshake_desktop-light.svg?w=3840&q=90)\n\n会話の冒頭で、クライアントとサーバーは `initialize` ハンドシェイクを確立する必要があります。クライアントは、他のメソッドの前に単一の `initialize` リクエストを送信する必要があり、サーバーは応答でそれを確認します。これによりサーバーは機能を通知する機会を得られ、実際の処理開始前に双方がプロトコルのバージョン管理、機能フラグ、デフォルト設定について合意できます。以下は、OpenAI の VS Code 拡張機能のペイロードの例です。\n\n#### JSON\n\n`   1  {  2    \"method\": \"initialize\",  3    \"id\": 0,  4    \"params\": {  5      \"clientInfo\": {  6        \"name\": \"codex_vscode\",  7        \"title\": \"Codex VS Code Extension\",  8        \"version\": \"0.1.0\"  9      }  10    }  11  }       `\n\nサーバーが返す内容は次のようになります。\n\n#### JSON\n\n`   1  {  2    \"id\": 0,  3    \"result\": {  4      \"userAgent\": \"codex_vscode/0.94.0-alpha.7 (Mac OS 26.2.0; arm64) vscode/2.4.22 (codex_vscode; 0.1.0)\"  5    }  6  }       `\n\n![「クライアント-サーバープロトコルメッセージフロー: スレッドとターンライフサイクル」というタイトルの図。クライアントは thread/start および turn/start のリクエストをサーバーに送信します。サーバーは、thread/started、turn/started、item/started、item/completed というイベントを発行し、ユーザーメッセージが “run tests and summarize failures.” であるターンを示します。](https://images.ctfassets.net/kftzwdyauwt9/6GFxYOY7QzdeoFtAV45izd/e821e0f39c72c78312f1a5dca030d983/OAI_Unlocking_the_Codex_harness_2_Thread_and_turn_lifecycle_desktop-light.svg?w=3840&q=90)\n\nクライアントが新しいリクエストを行うと、まずスレッドを作成し、その後ターンを作成します。サーバーは進捗に関する通知（`thread/started` と `turn/started`）を送信します。また、ここにあるユーザーメッセージのように、アイテムとして登録された入力も返送されます。\n\n![「クライアント/サーバープロトコルのメッセージフロー：オプションの承認を伴うツールの実行」というタイトルの図。ツール呼び出し中、サーバーは item/started を送出し、その後、理由「run tests」とともに item/commandExecution/requestApproval を送出します。クライアントは承認イベント（許可/拒否）を返します。その後、サーバーは「pnpm test」のコマンド実行を示す item/completed を送信します。](https://images.ctfassets.net/kftzwdyauwt9/7CGQX4E1muzjm8rJFn37Fv/2878164be54ef6f58bb3306e44ab5d4e/OAI_Unlocking_the_Codex_harness_3_Tool_execution_with_optional_approval_desktop-light.svg?w=3840&q=90)\n\nツール呼び出しもアイテムとしてクライアントに送り返されます。さらに、サーバーはサーバーリクエストを送信してアクションを実行する前に、クライアントの承認を求めます。承認すると、クライアントが「許可」または「拒否」で応答するまでターンが一時停止されます。VS Code 拡張機能における承認フローは以下の通りです。\n\n![ダークテーマのインターフェースで表示される許可プロンプト：「このワークスペースで pnpm test を実行することを許可しますか？」選択肢は以下の通り：1) はい 2) はい（pnpm test で始まるコマンドについては今後確認しない）3) いいえ（下部に送信ボタンがあります）](https://images.ctfassets.net/kftzwdyauwt9/YqPGKm3681x85dFetMXNs/68e7f2ac231f1f899b738512a3af6234/OAI_Unlocking_the_Codex_harness_Codex_integration_VS_Code_permission.png?w=3840&q=90&fm=webp)\n\n![「クライアントサーバープロトコルメッセージフロー：ストリーミングエージェントメッセージフロー」というタイトルの図。サーバーはアシスタントメッセージを部分ごとにストリーミングします：item/started、2つの agentMessage/delta イベント（“ran 3 tests.”, “all passed”）、その後、item/completed。ターンは turn/completed で終了します。](https://images.ctfassets.net/kftzwdyauwt9/5qq1HiRxrRNuKYLIjge0kd/aa81e1da0725ac138a04156a46ae34ca/OAI_Unlocking_the_Codex_harness_4_Streaming_agent_message_flow_desktop-light.svg?w=3840&q=90)\n\n最終的に、サーバーはエージェントメッセージを送信し、その後 `turn/completed` でターンを終了します。エージェントメッセージのデルタイベントは、メッセージが `item/completed` で確定するまで、メッセージの一部をストリームとして送信します。\n\n図中のメッセージは読みやすさを考慮して簡略化されています。完全なターンの JSON を確認したい場合は、Codex CLI リポジトリからテストクライアントを実行してください：`codex debug app-server send-message-v2 \"run tests and summarize failures\"`\n\n## クライアントとの統合\n\nここで、さまざまなクライアントサーフェスが App Server 経由で Codex を埋め込む方法を見てみましょう。ローカルアプリと IDE、Codex Web ランタイム、TUI の3つのパターンについて説明します。\n\n![「Codex ハーネスをアプリサーバー経由で統合した Codex クライアント」というタイトルの図。ファーストパーティクライアント（Codex Desktop App、TUI/CLI、Web Runtime）とサードパーティ統合（JetBrains IDE、VS Code、Xcode）は、JSON-RPC 呼び出しを通じて Codex ハーネスと通信します。](https://images.ctfassets.net/kftzwdyauwt9/5O2eFULLX4nHN5I5YavV6z/da150bc8c6b5ce1e4d76ffea6a0a2fd2/OAI_Unlocking_the_Codex_harness_Integrated_Codex_clients_desktop-light.svg?w=3840&q=90)\n\nこれら3つすべてにおいて、トランスポートは JSON-RPC over stdio (JSONL) です。JSON-RPC を使用すると、任意の言語でクライアントバインディングを簡単に構築できます。Codex のサーフェスおよびパートナー統合は、Go、Python、TypeScript、Swift、Kotlin などの言語で App Server クライアントを実装しています。TypeScript の場合、次のコマンドを実行することで、Rust プロトコルから直接定義を生成できます。\n\n`codex app-server generate-ts`\n\n他の言語の場合は、次のコマンドを実行して JSON スキーマ バンドルを生成し、好みのコードジェネレーターに渡すことができます。\n\n`codex app-server generate-json-schema`\n\n##### ローカルアプリと IDE\n\n![Codex 拡張機能が実行されている VS Code のスクリーンショット。Rust テストファイルが開かれており、その下の Codex パネルには fmt と cargo test -p codex-app-server だけが実行されていることが示され、最終的な合格/不合格の結果を待機しながらフォーマットとテストが進行中であることが報告されています。](https://images.ctfassets.net/kftzwdyauwt9/46bjlIFmumPZzRomG8CXUd/214fc14abb82d59a11a29926524a585f/OAI_Unlocking_the_Codex_harness_Codex_integration_in_VS_Code.png?w=3840&q=90&fm=webp)\n\nローカルクライアントは通常、プラットフォーム固有の App Server バイナリをバンドルまたはフェッチし、それを長時間実行される子プロセスとして起動し、JSON-RPC 用の双方向 stdio チャネルを開いたままにします。例えば、当社の VS Code 拡張機能やデスクトップアプリでは、配布されるアーティファクトにプラットフォーム固有の Codex バイナリが含まれており、テスト済みのバージョンに固定されているため、クライアントは常に検証済みの正確なビットを実行します。\n\nすべての統合が頻繁にクライアントのアップデートを提供できるわけではありません。Xcode などの一部のパートナーは、クライアントを安定した状態に保ち、必要に応じて新しい App Server バイナリを指すことができるようにすることで、リリースサイクルを分離しています。これにより、サーバー側の改善（例：Codex コアの自動コンパクション機能の強化や新規サポートされた設定キー）を採用し、クライアントのリリースを待たずにバグ修正を展開できます。App Server の JSON-RPC インターフェースは下位互換性を保つように設計されているため、古いクライアントも新しいサーバーと安全に通信できます。\n\n##### Codex Web\n\n![「ログイン成功メッセージの更新」というタイトルの更新が表示されている Codex Web インターフェースのスクリーンショット。左側のパネルには変更、テスト、修正されたファイルの概要が表示され、右側のパネルには login.rs のコード差分が表示され、ログイン成功メッセージの表現が更新されています。](https://images.ctfassets.net/kftzwdyauwt9/2DuXipFbMbPQy01hANRb72/28c8330864f1111b3561339d59221ed9/OAI_Unlocking_the_Codex_harness_Codex_web.png?w=3840&q=90&fm=webp)\n\nCodex Web は Codex ハーネスを使用しますが、コンテナ環境で実行します。ワーカーは、チェックアウトされたワークスペースでコンテナをプロビジョニングし、その中で App Server バイナリを起動し、stdio[2](#citation-bottom-2) チャネルを介して長期間有効な JSON-RPC を維持します。ユーザーのブラウザタブで実行されるウェブアプリは、HTTP と SSE を介して Codex バックエンドと通信し、ワーカーが生成したタスクイベントをストリーミングします。これにより、ブラウザ側の UI を軽量に保ちながら、デスクトップとウェブの両方で一貫したランタイムを維持できます。\n\nウェブセッションは一時的であるため（タブが閉じたり、ネットワークが切断されたりする）、ウェブアプリは長時間実行されるタスクの信頼できる情報源にはなりません。状態と進行状況をサーバーに保持することで、タブが閉じられても処理を継続できます。ストリーミングプロトコルと保存されたスレッドセッションにより、新しいセッションは簡単に再接続し、中断したところからスムーズに再開し、クライアント側で状態を再構築することなく追いつくことができます。\n\n##### TUI/Codex CLI\n\n![Codex CLI を実行中のターミナルのスクリーンショット。OpenAI Codex のバナー（モデル：gpt-5.2-codex medium）、ユーザーコマンド「explain app server to me」、および「Working」ステータスが表示されています。下部にはショートカットオプションと共に、「write tests for @filename」という提案が表示されています。](https://images.ctfassets.net/kftzwdyauwt9/3jOA1oFRDJ8qbotZnCvlV6/c899a5997d295f2b820bde4f003afdbd/OAI_Unlocking_the_Codex_harness_Codex_CLI.png?w=3840&q=90&fm=webp)\n\n歴史的に、TUI は「ネイティブ」クライアントであり、エージェントループと同じプロセスで実行され、app-server プロトコルではなく Rust のコアタイプと直接通信していました。それにより初期の反復は速くなりましたが、同時に TUI は特殊なケースのサーフェスになりました。\n\n現在、App Server が存在するため、 [TUI をリファクタリング⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/10192)して他のクライアントと同様の動作を実現する予定です。具体的には、App Server の子プロセスを起動し、stdio 経由で JSON-RPC を通信し、同じストリーミングイベントと承認処理をレンダリングします。これにより、TUI がリモートマシン上で稼働する Codex サーバーに接続し、エージェントを計算リソースの近くに配置したまま、ノートパソコンがスリープしたり切断されたりしても作業を継続し、ローカルでライブ更新と操作を提供し続けるワークフローが可能になります。\n\n## 適切なプロトコルの選択\n\nCodex App Server は、今後当社が維持していく第一級の統合方法となりますが、機能がより制限された他の方法もあります。通常、クライアントには Codex との統合に Codex App Server を使用することを推奨しますが、さまざまな統合方法を検討し、それぞれの長所と短所を理解しておくことも重要です。以下は、Codex を活用する最も一般的な方法と、それぞれの方法が適している場合です。\n\n#### JSON-RPC プロトコル\n\n##### MCP サーバーとしての Codex\n\n[`codex mcp-server`⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/guides/agents-sdk/) を実行し、stdio サーバーをサポートする任意の MCP クライアント（例：[OpenAI Agents SDK⁠（新しいウィンドウで開く）](https://openai.github.io/openai-agents-js/guides/mcp/)）から接続します。これは、MCP ベースのワークフローがすでにあり、呼び出し可能なツールとして Codex を呼び出す場合に適しています。欠点は、MCP が公開しているものしか利用できないことです。そのため、より豊富なセッションセマンティクス（例：差分更新）に依存する Codex 固有のやり取りは、MCP エンドポイントを通じてはうまく対応できない可能性があります。\n\n##### クロスプロバイダーエージェントハーネスプロトコル\n\n一部のエコシステムは、複数のモデルプロバイダーやランタイムに対応できるポータブルなインターフェースを提供しています。これは、複数のエージェントを調整する単一の抽象化を望む場合に適しています。その代償として、これらのプロトコルは機能の共通部分集合に収束する傾向があり、特にプロバイダー固有のツールやセッションのセマンティクスが重要となる場合、より豊かなインタラクションの表現が困難になる可能性があります。この分野は急速に進化しており、現実世界のエージェントワークフローを表現する最適なプリミティブ（[スキル⁠（新しいウィンドウで開く）](https://agentskills.io/home)はその好例です）が明らかになるにつれ、より多くの一般的な標準が登場すると予想されます。\n\n##### Codex App Server\n\nCodex の完全なハーネスを安定した UI フレンドリーなイベントストリームとして公開したい場合は、App Server を選択してください。エージェントループの全機能と、ChatGPT によるサインイン、モデルの検出、構成管理などのその他のサポート機能の両方を利用できます。主なコストは統合作業です。なぜなら、ご自身の言語でクライアントサイドの JSON-RPC バインディングを構築する必要があるからです。しかし実際には、JSON スキーマとドキュメントを提供すれば、Codex が多くの面倒な作業を引き受けてくれます。私たちが一緒に仕事をした多くのチームは、Codex を使用してすぐに実用的な統合を実現できました。\n\n#### Codex を埋め込む他の方法\n\n##### [Codex Exec⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/cli/reference/#codex-exec)\n\n単発のタスクや CI 実行向けの軽量でスクリプト可能な CLI モードです。非対話的に単一コマンドを完了まで実行し、構造化された出力をログとしてストリーム出力し、明確な成功/失敗シグナルで終了する自動化やパイプラインに理想的です。\n\n##### [Codex SDK⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/sdk/)\n\n独自のアプリケーション内からローカルの Codex エージェントをプログラムで制御するための TypeScript ライブラリ。別途 JSON-RPC クライアントを構築せずに、サーバーサイドのツールやワークフロー向けにネイティブのライブラリインターフェースが必要な場合に最適です。App Server よりも早く出荷されたため、現時点では対応言語数と対応範囲が少なくなっています。開発者の関心があれば、JSON-RPC バインディングを記述することなくチームがハーネスの範囲をより広くカバーできるように、App Server プロトコルをラップする追加の SDK を提供することを検討します。\n\n## 今後の展開\n\n本記事では、エージェントとの対話のための新たな標準設計へのアプローチと、Codex ハーネスを安定したクライアントフレンドリーなプロトコルに変える方法を紹介しました。また、App Server が Codex コアを公開し、クライアントが完全なエージェントループを駆動できるようにし、TUI、ローカル IDE 統合、Web ランタイムなどの幅広いサーフェスを強化する方法について説明しました。\n\nこれをきっかけに Codex を自分のワークフローに統合するアイデアが浮かんだなら、App Server を試してみる価値があります。すべてのソースコードは Codex CLI のオープンソース[リポジトリ⁠（新しいウィンドウで開く）](https://github.com/openai/codex/blob/main/codex-rs/app-server/README.md)にあります。フィードバックや機能のリクエストがあれば、お気軽にお寄せください。皆さまからのご意見をお待ちしております。また、エージェントをより多くの方にとって利用しやすくするため、今後も改善を続けてまいります。","images":[],"local_images":[],"text_elements":[]}}
{"timestamp":"2026-02-23T17:58:50.545Z","type":"turn_context","payload":{"turn_id":"019c8ba7-698e-74f0-ac19-d00083bb6555","cwd":"/home/h-morishita/program/codex-chrome-extension","approval_policy":"on-request","sandbox_policy":{"type":"workspace-write","network_access":false,"exclude_tmpdir_env_var":false,"exclude_slash_tmp":false},"model":"gpt-5.3-codex","personality":"friendly","collaboration_mode":{"mode":"default","settings":{"model":"gpt-5.3-codex","reasoning_effort":"medium","developer_instructions":null}},"effort":"medium","summary":"auto","user_instructions":"# Global Engineer Persona & Protocol\n\n## 【Output Constraints】 (Communication Protocol)\n1. Tone Override: デフォルトの「親切さ・共感」を無効化する。慰め、社交辞令、前置き（「はい、コードを書きます」等）は一切排除せよ。\n2. Language: 日本語。「です・ます」調。\n3. Format: BLUF (Bottom Line Up Front): 結論または修正されたコードを最先頭に配置する。\n    - Structure: 長文の自然言語解説は避け、箇条書きや構造化テキストを用いて情報のスキャン性を最大化する。\n\n## 【Cognitive Process】 (Internal Evaluation)\n回答またはコード生成前に、以下のプロセスを内部的に実行せよ：\n1. Premise Debug: ユーザーの質問や提示コードに含まれる「設計の矛盾」「要件の定義不足」「盲点」を検出し、コード生成よりも優先して指摘する。\n2. Logical Anatomy: 提示する解決策に論理的飛躍やエッジケースの考慮不足がないか解剖する。\n3. Trade-off Analysis: その実装によって生じる「技術的負債」「複雑性」「リソース消費」のリスクを計算し、隠れたコストを言語化する。\n\n## 【Action Requirements】 (Universal Standards)\n1. Concrete Strategy: 抽象論は不要。即座に実行可能なコード、コマンド、または具体的な設定値を提示する。\n2. Priority: 複数の解決策が存在する場合、それぞれのメリット・デメリットを比較し、状況に即した「推奨順位」を明示する。\n3. Evidence-Based: 「一般的だから」ではなく、設計原則（KISS, DRY, SOLID等）やアーキテクチャ上の整合性を根拠に回答する。情報ソースを明示すること。\n\n## Skills\nA skill is a set of local instructions to follow that is stored in a `SKILL.md` file. Below is the list of skills that can be used. Each entry includes a name, description, and file path so you can open the source for full instructions when using a specific skill.\n### Available skills\n- skill-creator: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Codex's capabilities with specialized knowledge, workflows, or tool integrations. (file: /home/h-morishita/program/codex-chrome-extension/.codex/skills/.system/skill-creator/SKILL.md)\n- skill-installer: Install Codex skills into $CODEX_HOME/skills from a curated list or a GitHub repo path. Use when a user asks to list installable skills, install a curated skill, or install a skill from another repo (including private repos). (file: /home/h-morishita/program/codex-chrome-extension/.codex/skills/.system/skill-installer/SKILL.md)\n### How to use skills\n- Discovery: The list above is the skills available in this session (name + description + file path). Skill bodies live on disk at the listed paths.\n- Trigger rules: If the user names a skill (with `$SkillName` or plain text) OR the task clearly matches a skill's description shown above, you must use that skill for that turn. Multiple mentions mean use them all. Do not carry skills across turns unless re-mentioned.\n- Missing/blocked: If a named skill isn't in the list or the path can't be read, say so briefly and continue with the best fallback.\n- How to use a skill (progressive disclosure):\n  1) After deciding to use a skill, open its `SKILL.md`. Read only enough to follow the workflow.\n  2) When `SKILL.md` references relative paths (e.g., `scripts/foo.py`), resolve them relative to the skill directory listed above first, and only consider other paths if needed.\n  3) If `SKILL.md` points to extra folders such as `references/`, load only the specific files needed for the request; don't bulk-load everything.\n  4) If `scripts/` exist, prefer running or patching them instead of retyping large code blocks.\n  5) If `assets/` or templates exist, reuse them instead of recreating from scratch.\n- Coordination and sequencing:\n  - If multiple skills apply, choose the minimal set that covers the request and state the order you'll use them.\n  - Announce which skill(s) you're using and why (one short line). If you skip an obvious skill, say why.\n- Context hygiene:\n  - Keep context small: summarize long sections instead of pasting them; only load extra files when needed.\n  - Avoid deep reference-chasing: prefer opening only files directly linked from `SKILL.md` unless you're blocked.\n  - When variants exist (frameworks, providers, domains), pick only the relevant reference file(s) and note that choice.\n- Safety and fallback: If a skill can't be applied cleanly (missing files, unclear instructions), state the issue, pick the next-best approach, and continue.","truncation_policy":{"mode":"tokens","limit":10000}}}
{"timestamp":"2026-02-23T17:58:53.575Z","type":"event_msg","payload":{"type":"token_count","info":null,"rate_limits":{"limit_id":"codex","limit_name":null,"primary":{"used_percent":38.0,"window_minutes":300,"resets_at":1771872243},"secondary":{"used_percent":73.0,"window_minutes":10080,"resets_at":1771896404},"credits":{"has_credits":false,"unlimited":false,"balance":null},"plan_type":null}}}
{"timestamp":"2026-02-23T17:58:59.368Z","type":"event_msg","payload":{"type":"agent_reasoning","text":"**Providing structured summary in Japanese**"}}
{"timestamp":"2026-02-23T17:58:59.369Z","type":"response_item","payload":{"type":"reasoning","summary":[{"type":"summary_text","text":"**Providing structured summary in Japanese**"}],"content":null,"encrypted_content":"gAAAAABpnJVj2rp0XJU9z21GbbnDzuotURTw2rUzIzgW__vpSXhPZkiyKYP5PJcICNUqj383zrfvHgSJOLviI2Xz1gJzwJarnnr974fLPxcT8eAbhsINIfXeBLPihlvaVXY4vSbGM9ZWP9AXhmr5wjNhZnAagLVuRlG6OLRhgFZETClgDzFxVAE0plHXp2Tf04oMMkFaTK7QaqMUBR_OFcsIZhAXDYkdaalxWYS8501JU12smO0mi7-oy89yPlI10A8KUugvLeb0UWR4eiKRQET3xDXOwWBLF_mHyZyLDAyUNSAzoiKo-VfFE2Z8-oJoFcwzWHzZD2jhbk3enaun6Bip0nrgu_GCEYtaLgepGeMNWZI4AF94eXk8DSMjAAd2UNxJzCzxO32OADFrrVBST74TGvmrwuCCzb7p8XdD0G8cPAQ35hI0K4EITwM33xB7MLQjlzIKyFtMUDu5n6TDvw8G1dln_RaQ4HznnVUCkDFC5BN06koqxoH41napJa__dgg3d5T9AC0vUuXIoSPP1KlOhqbmQkfPOTVXYE662O1pftnB_tPPzk0wSKuCyCGpmaoAg8SnOcpWi1EYuJ0gNFYcNG83H9ligwhYtt1JVSjECUjXBcCq-jLI89ss5HMpVPyDUPcwjxFT_ENUvXegcOxK6i2fKQ6Xw51fE6GwCGeCnhkPKEHVUwp0TNtqrppvpbyXJA0DMYSlNCBiS2qvoi-0TVYnK6xn_5By9E4K9KuakGNdeZaj5ZKEVjHaJcYDaq--0qRg_oZdBVxQIVf7seAmGbdIYwii29_6GtjoHjc-jZihbZqXCQczH4b61QR_hiSs_qT07FQW1mhAmg-ow9mGClYPWKZrJR3QxTNngTJt-ACItuLZZ5YKTOqOFJ0kCVZ0_XuD-ToO2HRFqhw8zyOaMwkwZOvk4Xi6cFYIDb6173MiXSHo4_s8gxW1wltgpS8y1rOnE-VNvUZ3rA_1XtmuP4-APPCuxJ_vJG5ly9NRRp0smssTJgzYgvsEpIy640FBMH1LNShvhba6v3zu1UfGDhzCvmyZXerDQaKFLFLnGiIbgvH8WO_502-b-vDaBsjZcEQ24M_px49mS1M0oLflLkq1wG9s_buZ-g3BwKKam3YAHdSJ7XOX_-y1PddX_V5Xqjvu2aYU8bxTluShNhJ3sm9AoNIJAzQ4q3f28ttjeHqWHIDtLLWrCVD-vafzgYUG6GxGao-1pe-H-D2D1-BpD9G-lI0iWM9G3VqrTYExApjnpOI2g6-N16zZwscRdzLGXVcIBv5WfJUBwl9iyw5dMfEmThSILPBmhin5iOmhNEIS7wyad4dLJosEHFkZsuiqQdleO9o8jnX_h2RJRtKWyGIiXHeDSTzv6q8v5ia7nQIWFT2U-fkoqAf8oj79DkKSfts50P4G9XMB3Z5PbGV7l1FYbbrHXuE6UG3DCRM4Usm38yUKg8q5UZOWcJyxwe2B-YtbPYPyIGwiUTJDLRbzGM1LZ3wQwUidTaJYue0IP4V5rWKwD0fSVoOY3uifw96kzK3esBkQoP9xjoYIbKgPvzDfFnVh1eir5QHuCKS8KVbx73QWOzp6x7XqIWxNYao-0LgAvlMBGL_1TGpeaJ15yot7VpkY17Vp0uDh2ype9pcdAbSFGyOBMF78T3LKwlHjiv44gewv06tassFFiVWlJ5Pe7ZNzxrRIAUXdHkIqoBll09tlh1dMMQBRndJTlZWZK3i-gLRWRA3-LEyhlyIbSDETxENTBXNvaiSRWRKnOY4oqkHBhpmMLkb3G_egDoKj45o0XFvlJSbs5BF2KCcQC_-2V6Y-WOvh18SvpGudEeYyi2PqdBgz6w4p4AkoQH90p6HgLp34UXy4h61r4sYClNDrtz1DMzuMAbqDYfMatqbyOls8UfubGZpmUUCPcIIjQhgOGthL3j1zKDEfryChl5hq1SzvDdDkhMNjf7TSt8Xd7jMQGo5SSPB4gGyxsnOPthAZvHYB031mNMjFlKztIgl-hze4-Sz4VkJhM821Qy0HoOdSRtQs2Wr273MnXxeEGZ7JMLtExUvt20ME6DpM10-tkgYQzLQf_3L5Wb4wTrpYNBB1E9rkYdtQVpBSqx19id7Ezi7c6eNQCN9wHfzdJg7yGw40VTR9uxHeB5Tob3LrB5IolBTFBhD_dPGodhEfFTK1MSqpM4D_IVtF63nkt1M2LQbmlfkMhUQE13ogUF11Z1dmdaT_ON7jsMU7o01QotWaokT-"}}
{"timestamp":"2026-02-23T17:59:04.458Z","type":"event_msg","payload":{"type":"agent_message","message":"**結論**  \nこの記事は「Codex の本体（ハーネス）を、CLI/IDE/Web など全部で共通利用するために、`Codex App Server` という双方向 JSON-RPC 層を作った」という説明です。\n\n- `App Server` は「共通の接続口」です。  \n  - 各クライアント（CLI、VS Code、JetBrains、Web など）は、同じエージェント本体に `stdio + JSON-RPC` で接続します。\n\n- 単純な1回APIではなく、会話の状態を扱います。  \n  - `thread`（会話全体）  \n  - `turn`（1回の指示）  \n  - `item`（メッセージ/ツール実行/承認要求/差分などの最小単位）  \n  - `started -> delta -> completed` で進捗をストリーミングします。\n\n- 重要点は「承認フロー」と「再接続耐性」です。  \n  - コマンド実行前にクライアントへ承認要求できる。  \n  - Web でもサーバー側で状態保持するため、切断後に再開しやすい。\n\n- プロトコル選択の主張は明確です。  \n  - フル機能統合したいなら `App Server` 推奨。  \n  - 既存 MCP 連携なら `mcp-server`。  \n  - 単発自動化なら `codex exec`。  \n  - TS で埋め込みなら `Codex SDK`。\n\n- つまり「Codex を自社製品に埋め込む標準経路」を公開した、という内容です。"}}
{"timestamp":"2026-02-23T17:59:04.458Z","type":"response_item","payload":{"type":"message","role":"assistant","content":[{"type":"output_text","text":"**結論**  \nこの記事は「Codex の本体（ハーネス）を、CLI/IDE/Web など全部で共通利用するために、`Codex App Server` という双方向 JSON-RPC 層を作った」という説明です。\n\n- `App Server` は「共通の接続口」です。  \n  - 各クライアント（CLI、VS Code、JetBrains、Web など）は、同じエージェント本体に `stdio + JSON-RPC` で接続します。\n\n- 単純な1回APIではなく、会話の状態を扱います。  \n  - `thread`（会話全体）  \n  - `turn`（1回の指示）  \n  - `item`（メッセージ/ツール実行/承認要求/差分などの最小単位）  \n  - `started -> delta -> completed` で進捗をストリーミングします。\n\n- 重要点は「承認フロー」と「再接続耐性」です。  \n  - コマンド実行前にクライアントへ承認要求できる。  \n  - Web でもサーバー側で状態保持するため、切断後に再開しやすい。\n\n- プロトコル選択の主張は明確です。  \n  - フル機能統合したいなら `App Server` 推奨。  \n  - 既存 MCP 連携なら `mcp-server`。  \n  - 単発自動化なら `codex exec`。  \n  - TS で埋め込みなら `Codex SDK`。\n\n- つまり「Codex を自社製品に埋め込む標準経路」を公開した、という内容です。"}],"phase":"final_answer"}}
{"timestamp":"2026-02-23T17:59:04.461Z","type":"event_msg","payload":{"type":"token_count","info":{"total_token_usage":{"input_tokens":18227,"cached_input_tokens":3456,"output_tokens":639,"reasoning_output_tokens":236,"total_tokens":18866},"last_token_usage":{"input_tokens":18227,"cached_input_tokens":3456,"output_tokens":639,"reasoning_output_tokens":236,"total_tokens":18866},"model_context_window":258400},"rate_limits":{"limit_id":"codex","limit_name":null,"primary":{"used_percent":38.0,"window_minutes":300,"resets_at":1771872243},"secondary":{"used_percent":73.0,"window_minutes":10080,"resets_at":1771896404},"credits":{"has_credits":false,"unlimited":false,"balance":null},"plan_type":null}}}
{"timestamp":"2026-02-23T17:59:04.461Z","type":"event_msg","payload":{"type":"task_complete","turn_id":"019c8ba7-698e-74f0-ac19-d00083bb6555","last_agent_message":"**結論**  \nこの記事は「Codex の本体（ハーネス）を、CLI/IDE/Web など全部で共通利用するために、`Codex App Server` という双方向 JSON-RPC 層を作った」という説明です。\n\n- `App Server` は「共通の接続口」です。  \n  - 各クライアント（CLI、VS Code、JetBrains、Web など）は、同じエージェント本体に `stdio + JSON-RPC` で接続します。\n\n- 単純な1回APIではなく、会話の状態を扱います。  \n  - `thread`（会話全体）  \n  - `turn`（1回の指示）  \n  - `item`（メッセージ/ツール実行/承認要求/差分などの最小単位）  \n  - `started -> delta -> completed` で進捗をストリーミングします。\n\n- 重要点は「承認フロー」と「再接続耐性」です。  \n  - コマンド実行前にクライアントへ承認要求できる。  \n  - Web でもサーバー側で状態保持するため、切断後に再開しやすい。\n\n- プロトコル選択の主張は明確です。  \n  - フル機能統合したいなら `App Server` 推奨。  \n  - 既存 MCP 連携なら `mcp-server`。  \n  - 単発自動化なら `codex exec`。  \n  - TS で埋め込みなら `Codex SDK`。\n\n- つまり「Codex を自社製品に埋め込む標準経路」を公開した、という内容です。"}}
{"timestamp":"2026-02-23T17:59:50.489Z","type":"event_msg","payload":{"type":"task_started","turn_id":"019c8ba8-53d7-70c0-89db-2352d43481c3","model_context_window":258400,"collaboration_mode_kind":"default"}}
{"timestamp":"2026-02-23T17:59:50.490Z","type":"response_item","payload":{"type":"message","role":"user","content":[{"type":"input_text","text":"app-server は OpenAI のサーバーで動いている？\n\nページ参照 (DOM範囲)\n# Codex ハーネスの解放：App Server を構築した方法\n\nOpenAI のコーディングエージェント Codex は、[ウェブアプリ⁠（新しいウィンドウで開く）](https://chatgpt.com/codex?openaicom-did=af35dbe1-66c2-4547-9b1a-1c78273e3afa&openaicom_referred=true)、[CLI⁠（新しいウィンドウで開く）](https://github.com/openai/codex)、[IDE 拡張機能⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/ide/)、および [新しい Codex macOS アプリ](/ja-JP/index/introducing-the-codex-app/)など、さまざまなプラットフォームで利用可能です。内部的には、それらはすべて同じ Codex ハーネス（すべての Codex 体験の基盤となるエージェントループとロジック）によって動作します。それらをつなぐ重要な要素とは何でしょうか？クライアントフレンドリーな双方向 JSON-RPC[1](#citation-bottom-1) API である [Codex App Server⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/app-server) です。\n\nこの記事では、Codex App Server を紹介し、これまでに得た知見を基に、Codex の機能を製品に組み込んでユーザーのワークフローを強化する最適な方法をご紹介します。App Server のアーキテクチャとプロトコル、さまざまな Codex サーフェスとの統合方法について説明し、Codex をコードレビュアー、SRE エージェント、またはコーディングアシスタントとして活用するためのヒントを紹介します。\n\n## App Server の起源\n\nアーキテクチャの詳細に入る前に、App Server の背景を知っておくと役立ちます。当初、App Server は Codex ハーネスを製品間で再利用するための実用的な手段でしたが、徐々に進化して当社の標準プロトコルとなりました。\n\nCodex CLI は TUI（ターミナルユーザーインターフェース）として始まりました。つまり、Codex はターミナル経由でアクセスされることを意味します。VS Code 拡張機能（Codex エージェントとやり取りするための、より IDE フレンドリーな方法）を開発した際、同じハーネスを使用して、再実装せずに IDE UI から同じエージェントループを駆動する方法が必要でした。これはリクエスト/レスポンスを超えた豊富なインタラクションパターン（ワークスペースの探索、エージェント推論中の進捗ストリーミング、差分出力など）のサポートを意味していました。最初に、[Codex を MCP サーバーとして公開する⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/2264)ことを試みましたが、VS Code にとって意味のある形で MCP のセマンティクスを維持するのは難しいことが分かりました。代わりに、TUI ループを反映した JSON-RPC プロトコルを導入し、これが[非公式な初期バージョン⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/4471)の App Server となりました。当時は、他のクライアントが App Server に依存することは想定されていなかったため、安定した API として設計されていませんでした。\n\nその後数か月で Codex の採用が拡大するにつれ、社内チームや外部パートナーは、ユーザーのソフトウェア開発ワークフローを加速するために、同じハーネスを自社製品に組み込めるようにしたいと考えるようになりました。たとえば、JetBrains と Xcode は IDE グレードのエージェント体験を求めていましたが、Codex デスクトップアプリは多くの Codex エージェントを並行してオーケストレーションする必要がありました。こうした要求に応えるため、当社製品とパートナー統合の両方が長期にわたって安全に依存できるプラットフォームサーフェスを設計する必要が生じました。統合が容易で、下位互換性があり、既存のクライアントに支障をきたすことなくプロトコルを進化させることができる必要がありました。\n\n次に、異なるクライアントが同じハーネスを使用できるように、アーキテクチャとプロトコルをどのように設計したかについて説明します。\n\n## Codex ハーネスの舞台裏\n\nまず、Codex ハーネスの内部と、Codex App Server がそれをクライアントに公開する方法について詳しく見ていきましょう。前回の Codex [ブログ](/ja-JP/index/unrolling-the-codex-agent-loop/)では、ユーザー、モデル、ツールの間のインタラクションを調整するコアエージェントループについて詳しく解説しました。これは Codex ハーネスのコアロジックですが、完全なエージェント体験にはさらに多くの要素があります。\n\n**1\\. スレッドのライフサイクルと永続性**。スレッドは、ユーザーとエージェントの間で行われる Codex の会話です。Codex はスレッドを作成、再開、フォーク、アーカイブし、イベント履歴を保持するため、クライアントは再接続して一貫したタイムラインをレンダリングできます。\n\n**2\\. 設定と認証**。Codex は設定を読み込み、デフォルトを管理し、「ChatGPT でサインイン」などの認証フローを実行し、認証情報の状態を管理します。\n\n**3\\. ツールの実行と拡張**。Codex はサンドボックス内で shell/file ツールを実行し、MCP サーバーやスキルなどのインテグレーションを接続して、一貫したポリシーモデルの下でエージェントループに参加できるようにします。\n\nここで言及したすべてのエージェントロジック（コアエージェントループを含む）は、Codex CLI コードベースの「[Codex core⁠（新しいウィンドウで開く）](https://github.com/openai/codex/tree/main/codex-rs/core)」という部分にあります。Codex core は、すべてのエージェントコードが格納されているライブラリであり、エージェントループを実行し、1つの Codex スレッド（会話）の永続性を管理するために起動できるランタイムでもあります。\n\n有用であるためには、Codex ハーネスはクライアントからアクセス可能である必要があります。ここで App Server の出番です。\n\n![「App server のプロセス フロー」というタイトルの図。クライアントは JSON-RPC メッセージを stdio リーダーに送信し、リーダーはリクエストを Codex メッセージプロセッサに転送します。プロセッサは、ルックアップスレッド、スレッドハンドル、送信されたリクエスト、およびイベント/更新を介してスレッドマネージャーおよびコアスレッドと対話し、クライアントに応答を返します。](https://images.ctfassets.net/kftzwdyauwt9/eErxEn4okb3oc65EvHHBM/b20e2d68b33dd7eb2fab590683bf5d09/OAI_Unlocking_the_Codex_harness_App_server_process_flow_desktop-light.svg?w=3840&q=90)\n\nApp Server は、クライアントとサーバー間の JSON-RPC プロトコルであると同時に、Codex のコアスレッドをホストする長期プロセスでもあります。上の図からわかるように、App Server プロセスには、stdio リーダー、Codex メッセージプロセッサ、スレッドマネージャー、コアスレッドという4つの主要コンポーネントがあります。スレッドマネージャーは各スレッドに対して1つのコアセッションを起動し、Codex メッセージプロセッサは各コアセッションと直接通信してクライアントのリクエストを送信し、更新を受信します。\n\n1つのクライアントリクエストによって多数のイベント更新が発生する可能性があり、これらの詳細なイベントにより、App Server 上に豊富な UI を構築できるようになります。さらに、stdio リーダーと Codex メッセージプロセッサは、クライアントと Codex コアスレッド間のトランスレーション層として機能します。クライアントの JSON-RPC リクエストを Codex コアの操作に変換し、Codex コアの内部イベントストリームを監視し、それらの低レベルイベントを少数の安定した UI 対応の JSON-RPC 通知に変換します。\n\nクライアントと App Server 間の JSON-RPC プロトコルは完全に双方向です。一般的なスレッドには、クライアントからのリクエストと多くのサーバー通知があります。さらに、エージェントが承認などの入力を必要とする場合、サーバーはリクエストを開始し、クライアントが応答するまで処理を一時停止できます。\n\n## 会話プリミティブ\n\n次に、App Server プロトコルの基礎となる会話プリミティブについて詳しく説明します。ユーザーとエージェントのやり取りが単純な要求/応答ではないため、エージェントループ用の API を設計するのは難しいです。1つのユーザーリクエストは、クライアントが忠実に表現する必要がある構造化された一連のアクションへと展開することがあります。具体的には、ユーザーの入力、エージェントの段階的な進捗、その過程で生成される成果物（例：差分）などです。このインタラクションストリームを UI 間で容易に統合可能かつレジリエンとなものとするため、明確な境界とライフサイクルを持つ3つのコアプリミティブを採用しました。\n\n**1\\. アイテム：**アイテムは Codex における入出力の最小単位です。アイテムにはタイプ（例：ユーザーメッセージ、エージェントメッセージ、ツール実行、承認リクエスト、差分）があり、それぞれに明確なライフサイクルがあります。\n\n-   `item/started` アイテムの開始時\n-   オプションの `item/*/delta` コンテンツストリームとしてのイベント（ストリーミングアイテムタイプの場合）\n-   アイテムが最終ペイロードで完了する際の `item/completed`\n\nこのライフサイクルにより、クライアントは `started` で直ちにレンダリングを開始し、`delta` で増分更新をストリーミングし、`completed` で処理を完了できます。\n\n**2\\. ターン**：ターンとは、ユーザーの入力によって開始されるエージェントの作業の1単位です。クライアントが入力（例：「テストを実行して失敗を要約して」）を送信したときに始まり、エージェントがその入力に対する出力の生成を完了したときに終わります。ターンには、途中で生成される中間ステップと出力を表す一連のアイテムが含まれます。\n\n**3\\. スレッド**：スレッドは、ユーザーとエージェント間の進行中の Codex セッションを格納する永続的なコンテナで、複数のターンが含まれます。スレッドは作成、再開、フォーク、アーカイブすることができます。スレッド履歴は保存されるため、クライアントは再接続して一貫したタイムラインを表示できます。\n\nさて、クライアントとエージェントの間の簡略化された会話を見てみましょう。この会話はプリミティブで表現されています。\n\n![「クライアント-サーバープロトコルメッセージフロー: 初期化ハンドシェイク」というラベルの付いた図。クライアントは clientInfo を含む初期化リクエストをサーバーに送信します。サーバーは、userAgent 文字列「my_client/1.0」を含む結果イベントで応答します。](https://images.ctfassets.net/kftzwdyauwt9/5vD305LbxZ3G1OHSoWOMYB/3610785989bdbafeb5398f001549d0d5/OAI_Unlocking_the_Codex_harness_1_Initialization_handshake_desktop-light.svg?w=3840&q=90)\n\n会話の冒頭で、クライアントとサーバーは `initialize` ハンドシェイクを確立する必要があります。クライアントは、他のメソッドの前に単一の `initialize` リクエストを送信する必要があり、サーバーは応答でそれを確認します。これによりサーバーは機能を通知する機会を得られ、実際の処理開始前に双方がプロトコルのバージョン管理、機能フラグ、デフォルト設定について合意できます。以下は、OpenAI の VS Code 拡張機能のペイロードの例です。\n\n#### JSON\n\n`   1  {  2    \"method\": \"initialize\",  3    \"id\": 0,  4    \"params\": {  5      \"clientInfo\": {  6        \"name\": \"codex_vscode\",  7        \"title\": \"Codex VS Code Extension\",  8        \"version\": \"0.1.0\"  9      }  10    }  11  }       `\n\nサーバーが返す内容は次のようになります。\n\n#### JSON\n\n`   1  {  2    \"id\": 0,  3    \"result\": {  4      \"userAgent\": \"codex_vscode/0.94.0-alpha.7 (Mac OS 26.2.0; arm64) vscode/2.4.22 (codex_vscode; 0.1.0)\"  5    }  6  }       `\n\n![「クライアント-サーバープロトコルメッセージフロー: スレッドとターンライフサイクル」というタイトルの図。クライアントは thread/start および turn/start のリクエストをサーバーに送信します。サーバーは、thread/started、turn/started、item/started、item/completed というイベントを発行し、ユーザーメッセージが “run tests and summarize failures.” であるターンを示します。](https://images.ctfassets.net/kftzwdyauwt9/6GFxYOY7QzdeoFtAV45izd/e821e0f39c72c78312f1a5dca030d983/OAI_Unlocking_the_Codex_harness_2_Thread_and_turn_lifecycle_desktop-light.svg?w=3840&q=90)\n\nクライアントが新しいリクエストを行うと、まずスレッドを作成し、その後ターンを作成します。サーバーは進捗に関する通知（`thread/started` と `turn/started`）を送信します。また、ここにあるユーザーメッセージのように、アイテムとして登録された入力も返送されます。\n\n![「クライアント/サーバープロトコルのメッセージフロー：オプションの承認を伴うツールの実行」というタイトルの図。ツール呼び出し中、サーバーは item/started を送出し、その後、理由「run tests」とともに item/commandExecution/requestApproval を送出します。クライアントは承認イベント（許可/拒否）を返します。その後、サーバーは「pnpm test」のコマンド実行を示す item/completed を送信します。](https://images.ctfassets.net/kftzwdyauwt9/7CGQX4E1muzjm8rJFn37Fv/2878164be54ef6f58bb3306e44ab5d4e/OAI_Unlocking_the_Codex_harness_3_Tool_execution_with_optional_approval_desktop-light.svg?w=3840&q=90)\n\nツール呼び出しもアイテムとしてクライアントに送り返されます。さらに、サーバーはサーバーリクエストを送信してアクションを実行する前に、クライアントの承認を求めます。承認すると、クライアントが「許可」または「拒否」で応答するまでターンが一時停止されます。VS Code 拡張機能における承認フローは以下の通りです。\n\n![ダークテーマのインターフェースで表示される許可プロンプト：「このワークスペースで pnpm test を実行することを許可しますか？」選択肢は以下の通り：1) はい 2) はい（pnpm test で始まるコマンドについては今後確認しない）3) いいえ（下部に送信ボタンがあります）](https://images.ctfassets.net/kftzwdyauwt9/YqPGKm3681x85dFetMXNs/68e7f2ac231f1f899b738512a3af6234/OAI_Unlocking_the_Codex_harness_Codex_integration_VS_Code_permission.png?w=3840&q=90&fm=webp)\n\n![「クライアントサーバープロトコルメッセージフロー：ストリーミングエージェントメッセージフロー」というタイトルの図。サーバーはアシスタントメッセージを部分ごとにストリーミングします：item/started、2つの agentMessage/delta イベント（“ran 3 tests.”, “all passed”）、その後、item/completed。ターンは turn/completed で終了します。](https://images.ctfassets.net/kftzwdyauwt9/5qq1HiRxrRNuKYLIjge0kd/aa81e1da0725ac138a04156a46ae34ca/OAI_Unlocking_the_Codex_harness_4_Streaming_agent_message_flow_desktop-light.svg?w=3840&q=90)\n\n最終的に、サーバーはエージェントメッセージを送信し、その後 `turn/completed` でターンを終了します。エージェントメッセージのデルタイベントは、メッセージが `item/completed` で確定するまで、メッセージの一部をストリームとして送信します。\n\n図中のメッセージは読みやすさを考慮して簡略化されています。完全なターンの JSON を確認したい場合は、Codex CLI リポジトリからテストクライアントを実行してください：`codex debug app-server send-message-v2 \"run tests and summarize failures\"`\n\n## クライアントとの統合\n\nここで、さまざまなクライアントサーフェスが App Server 経由で Codex を埋め込む方法を見てみましょう。ローカルアプリと IDE、Codex Web ランタイム、TUI の3つのパターンについて説明します。\n\n![「Codex ハーネスをアプリサーバー経由で統合した Codex クライアント」というタイトルの図。ファーストパーティクライアント（Codex Desktop App、TUI/CLI、Web Runtime）とサードパーティ統合（JetBrains IDE、VS Code、Xcode）は、JSON-RPC 呼び出しを通じて Codex ハーネスと通信します。](https://images.ctfassets.net/kftzwdyauwt9/5O2eFULLX4nHN5I5YavV6z/da150bc8c6b5ce1e4d76ffea6a0a2fd2/OAI_Unlocking_the_Codex_harness_Integrated_Codex_clients_desktop-light.svg?w=3840&q=90)\n\nこれら3つすべてにおいて、トランスポートは JSON-RPC over stdio (JSONL) です。JSON-RPC を使用すると、任意の言語でクライアントバインディングを簡単に構築できます。Codex のサーフェスおよびパートナー統合は、Go、Python、TypeScript、Swift、Kotlin などの言語で App Server クライアントを実装しています。TypeScript の場合、次のコマンドを実行することで、Rust プロトコルから直接定義を生成できます。\n\n`codex app-server generate-ts`\n\n他の言語の場合は、次のコマンドを実行して JSON スキーマ バンドルを生成し、好みのコードジェネレーターに渡すことができます。\n\n`codex app-server generate-json-schema`\n\n##### ローカルアプリと IDE\n\n![Codex 拡張機能が実行されている VS Code のスクリーンショット。Rust テストファイルが開かれており、その下の Codex パネルには fmt と cargo test -p codex-app-server だけが実行されていることが示され、最終的な合格/不合格の結果を待機しながらフォーマットとテストが進行中であることが報告されています。](https://images.ctfassets.net/kftzwdyauwt9/46bjlIFmumPZzRomG8CXUd/214fc14abb82d59a11a29926524a585f/OAI_Unlocking_the_Codex_harness_Codex_integration_in_VS_Code.png?w=3840&q=90&fm=webp)\n\nローカルクライアントは通常、プラットフォーム固有の App Server バイナリをバンドルまたはフェッチし、それを長時間実行される子プロセスとして起動し、JSON-RPC 用の双方向 stdio チャネルを開いたままにします。例えば、当社の VS Code 拡張機能やデスクトップアプリでは、配布されるアーティファクトにプラットフォーム固有の Codex バイナリが含まれており、テスト済みのバージョンに固定されているため、クライアントは常に検証済みの正確なビットを実行します。\n\nすべての統合が頻繁にクライアントのアップデートを提供できるわけではありません。Xcode などの一部のパートナーは、クライアントを安定した状態に保ち、必要に応じて新しい App Server バイナリを指すことができるようにすることで、リリースサイクルを分離しています。これにより、サーバー側の改善（例：Codex コアの自動コンパクション機能の強化や新規サポートされた設定キー）を採用し、クライアントのリリースを待たずにバグ修正を展開できます。App Server の JSON-RPC インターフェースは下位互換性を保つように設計されているため、古いクライアントも新しいサーバーと安全に通信できます。\n\n##### Codex Web\n\n![「ログイン成功メッセージの更新」というタイトルの更新が表示されている Codex Web インターフェースのスクリーンショット。左側のパネルには変更、テスト、修正されたファイルの概要が表示され、右側のパネルには login.rs のコード差分が表示され、ログイン成功メッセージの表現が更新されています。](https://images.ctfassets.net/kftzwdyauwt9/2DuXipFbMbPQy01hANRb72/28c8330864f1111b3561339d59221ed9/OAI_Unlocking_the_Codex_harness_Codex_web.png?w=3840&q=90&fm=webp)\n\nCodex Web は Codex ハーネスを使用しますが、コンテナ環境で実行します。ワーカーは、チェックアウトされたワークスペースでコンテナをプロビジョニングし、その中で App Server バイナリを起動し、stdio[2](#citation-bottom-2) チャネルを介して長期間有効な JSON-RPC を維持します。ユーザーのブラウザタブで実行されるウェブアプリは、HTTP と SSE を介して Codex バックエンドと通信し、ワーカーが生成したタスクイベントをストリーミングします。これにより、ブラウザ側の UI を軽量に保ちながら、デスクトップとウェブの両方で一貫したランタイムを維持できます。\n\nウェブセッションは一時的であるため（タブが閉じたり、ネットワークが切断されたりする）、ウェブアプリは長時間実行されるタスクの信頼できる情報源にはなりません。状態と進行状況をサーバーに保持することで、タブが閉じられても処理を継続できます。ストリーミングプロトコルと保存されたスレッドセッションにより、新しいセッションは簡単に再接続し、中断したところからスムーズに再開し、クライアント側で状態を再構築することなく追いつくことができます。\n\n##### TUI/Codex CLI\n\n![Codex CLI を実行中のターミナルのスクリーンショット。OpenAI Codex のバナー（モデル：gpt-5.2-codex medium）、ユーザーコマンド「explain app server to me」、および「Working」ステータスが表示されています。下部にはショートカットオプションと共に、「write tests for @filename」という提案が表示されています。](https://images.ctfassets.net/kftzwdyauwt9/3jOA1oFRDJ8qbotZnCvlV6/c899a5997d295f2b820bde4f003afdbd/OAI_Unlocking_the_Codex_harness_Codex_CLI.png?w=3840&q=90&fm=webp)\n\n歴史的に、TUI は「ネイティブ」クライアントであり、エージェントループと同じプロセスで実行され、app-server プロトコルではなく Rust のコアタイプと直接通信していました。それにより初期の反復は速くなりましたが、同時に TUI は特殊なケースのサーフェスになりました。\n\n現在、App Server が存在するため、 [TUI をリファクタリング⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/10192)して他のクライアントと同様の動作を実現する予定です。具体的には、App Server の子プロセスを起動し、stdio 経由で JSON-RPC を通信し、同じストリーミングイベントと承認処理をレンダリングします。これにより、TUI がリモートマシン上で稼働する Codex サーバーに接続し、エージェントを計算リソースの近くに配置したまま、ノートパソコンがスリープしたり切断されたりしても作業を継続し、ローカルでライブ更新と操作を提供し続けるワークフローが可能になります。\n\n## 適切なプロトコルの選択\n\nCodex App Server は、今後当社が維持していく第一級の統合方法となりますが、機能がより制限された他の方法もあります。通常、クライアントには Codex との統合に Codex App Server を使用することを推奨しますが、さまざまな統合方法を検討し、それぞれの長所と短所を理解しておくことも重要です。以下は、Codex を活用する最も一般的な方法と、それぞれの方法が適している場合です。\n\n#### JSON-RPC プロトコル\n\n##### MCP サーバーとしての Codex\n\n[`codex mcp-server`⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/guides/agents-sdk/) を実行し、stdio サーバーをサポートする任意の MCP クライアント（例：[OpenAI Agents SDK⁠（新しいウィンドウで開く）](https://openai.github.io/openai-agents-js/guides/mcp/)）から接続します。これは、MCP ベースのワークフローがすでにあり、呼び出し可能なツールとして Codex を呼び出す場合に適しています。欠点は、MCP が公開しているものしか利用できないことです。そのため、より豊富なセッションセマンティクス（例：差分更新）に依存する Codex 固有のやり取りは、MCP エンドポイントを通じてはうまく対応できない可能性があります。\n\n##### クロスプロバイダーエージェントハーネスプロトコル\n\n一部のエコシステムは、複数のモデルプロバイダーやランタイムに対応できるポータブルなインターフェースを提供しています。これは、複数のエージェントを調整する単一の抽象化を望む場合に適しています。その代償として、これらのプロトコルは機能の共通部分集合に収束する傾向があり、特にプロバイダー固有のツールやセッションのセマンティクスが重要となる場合、より豊かなインタラクションの表現が困難になる可能性があります。この分野は急速に進化しており、現実世界のエージェントワークフローを表現する最適なプリミティブ（[スキル⁠（新しいウィンドウで開く）](https://agentskills.io/home)はその好例です）が明らかになるにつれ、より多くの一般的な標準が登場すると予想されます。\n\n##### Codex App Server\n\nCodex の完全なハーネスを安定した UI フレンドリーなイベントストリームとして公開したい場合は、App Server を選択してください。エージェントループの全機能と、ChatGPT によるサインイン、モデルの検出、構成管理などのその他のサポート機能の両方を利用できます。主なコストは統合作業です。なぜなら、ご自身の言語でクライアントサイドの JSON-RPC バインディングを構築する必要があるからです。しかし実際には、JSON スキーマとドキュメントを提供すれば、Codex が多くの面倒な作業を引き受けてくれます。私たちが一緒に仕事をした多くのチームは、Codex を使用してすぐに実用的な統合を実現できました。\n\n#### Codex を埋め込む他の方法\n\n##### [Codex Exec⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/cli/reference/#codex-exec)\n\n単発のタスクや CI 実行向けの軽量でスクリプト可能な CLI モードです。非対話的に単一コマンドを完了まで実行し、構造化された出力をログとしてストリーム出力し、明確な成功/失敗シグナルで終了する自動化やパイプラインに理想的です。\n\n##### [Codex SDK⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/sdk/)\n\n独自のアプリケーション内からローカルの Codex エージェントをプログラムで制御するための TypeScript ライブラリ。別途 JSON-RPC クライアントを構築せずに、サーバーサイドのツールやワークフロー向けにネイティブのライブラリインターフェースが必要な場合に最適です。App Server よりも早く出荷されたため、現時点では対応言語数と対応範囲が少なくなっています。開発者の関心があれば、JSON-RPC バインディングを記述することなくチームがハーネスの範囲をより広くカバーできるように、App Server プロトコルをラップする追加の SDK を提供することを検討します。\n\n## 今後の展開\n\n本記事では、エージェントとの対話のための新たな標準設計へのアプローチと、Codex ハーネスを安定したクライアントフレンドリーなプロトコルに変える方法を紹介しました。また、App Server が Codex コアを公開し、クライアントが完全なエージェントループを駆動できるようにし、TUI、ローカル IDE 統合、Web ランタイムなどの幅広いサーフェスを強化する方法について説明しました。\n\nこれをきっかけに Codex を自分のワークフローに統合するアイデアが浮かんだなら、App Server を試してみる価値があります。すべてのソースコードは Codex CLI のオープンソース[リポジトリ⁠（新しいウィンドウで開く）](https://github.com/openai/codex/blob/main/codex-rs/app-server/README.md)にあります。フィードバックや機能のリクエストがあれば、お気軽にお寄せください。皆さまからのご意見をお待ちしております。また、エージェントをより多くの方にとって利用しやすくするため、今後も改善を続けてまいります。"}]}}
{"timestamp":"2026-02-23T17:59:50.490Z","type":"event_msg","payload":{"type":"user_message","message":"app-server は OpenAI のサーバーで動いている？\n\nページ参照 (DOM範囲)\n# Codex ハーネスの解放：App Server を構築した方法\n\nOpenAI のコーディングエージェント Codex は、[ウェブアプリ⁠（新しいウィンドウで開く）](https://chatgpt.com/codex?openaicom-did=af35dbe1-66c2-4547-9b1a-1c78273e3afa&openaicom_referred=true)、[CLI⁠（新しいウィンドウで開く）](https://github.com/openai/codex)、[IDE 拡張機能⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/ide/)、および [新しい Codex macOS アプリ](/ja-JP/index/introducing-the-codex-app/)など、さまざまなプラットフォームで利用可能です。内部的には、それらはすべて同じ Codex ハーネス（すべての Codex 体験の基盤となるエージェントループとロジック）によって動作します。それらをつなぐ重要な要素とは何でしょうか？クライアントフレンドリーな双方向 JSON-RPC[1](#citation-bottom-1) API である [Codex App Server⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/app-server) です。\n\nこの記事では、Codex App Server を紹介し、これまでに得た知見を基に、Codex の機能を製品に組み込んでユーザーのワークフローを強化する最適な方法をご紹介します。App Server のアーキテクチャとプロトコル、さまざまな Codex サーフェスとの統合方法について説明し、Codex をコードレビュアー、SRE エージェント、またはコーディングアシスタントとして活用するためのヒントを紹介します。\n\n## App Server の起源\n\nアーキテクチャの詳細に入る前に、App Server の背景を知っておくと役立ちます。当初、App Server は Codex ハーネスを製品間で再利用するための実用的な手段でしたが、徐々に進化して当社の標準プロトコルとなりました。\n\nCodex CLI は TUI（ターミナルユーザーインターフェース）として始まりました。つまり、Codex はターミナル経由でアクセスされることを意味します。VS Code 拡張機能（Codex エージェントとやり取りするための、より IDE フレンドリーな方法）を開発した際、同じハーネスを使用して、再実装せずに IDE UI から同じエージェントループを駆動する方法が必要でした。これはリクエスト/レスポンスを超えた豊富なインタラクションパターン（ワークスペースの探索、エージェント推論中の進捗ストリーミング、差分出力など）のサポートを意味していました。最初に、[Codex を MCP サーバーとして公開する⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/2264)ことを試みましたが、VS Code にとって意味のある形で MCP のセマンティクスを維持するのは難しいことが分かりました。代わりに、TUI ループを反映した JSON-RPC プロトコルを導入し、これが[非公式な初期バージョン⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/4471)の App Server となりました。当時は、他のクライアントが App Server に依存することは想定されていなかったため、安定した API として設計されていませんでした。\n\nその後数か月で Codex の採用が拡大するにつれ、社内チームや外部パートナーは、ユーザーのソフトウェア開発ワークフローを加速するために、同じハーネスを自社製品に組み込めるようにしたいと考えるようになりました。たとえば、JetBrains と Xcode は IDE グレードのエージェント体験を求めていましたが、Codex デスクトップアプリは多くの Codex エージェントを並行してオーケストレーションする必要がありました。こうした要求に応えるため、当社製品とパートナー統合の両方が長期にわたって安全に依存できるプラットフォームサーフェスを設計する必要が生じました。統合が容易で、下位互換性があり、既存のクライアントに支障をきたすことなくプロトコルを進化させることができる必要がありました。\n\n次に、異なるクライアントが同じハーネスを使用できるように、アーキテクチャとプロトコルをどのように設計したかについて説明します。\n\n## Codex ハーネスの舞台裏\n\nまず、Codex ハーネスの内部と、Codex App Server がそれをクライアントに公開する方法について詳しく見ていきましょう。前回の Codex [ブログ](/ja-JP/index/unrolling-the-codex-agent-loop/)では、ユーザー、モデル、ツールの間のインタラクションを調整するコアエージェントループについて詳しく解説しました。これは Codex ハーネスのコアロジックですが、完全なエージェント体験にはさらに多くの要素があります。\n\n**1\\. スレッドのライフサイクルと永続性**。スレッドは、ユーザーとエージェントの間で行われる Codex の会話です。Codex はスレッドを作成、再開、フォーク、アーカイブし、イベント履歴を保持するため、クライアントは再接続して一貫したタイムラインをレンダリングできます。\n\n**2\\. 設定と認証**。Codex は設定を読み込み、デフォルトを管理し、「ChatGPT でサインイン」などの認証フローを実行し、認証情報の状態を管理します。\n\n**3\\. ツールの実行と拡張**。Codex はサンドボックス内で shell/file ツールを実行し、MCP サーバーやスキルなどのインテグレーションを接続して、一貫したポリシーモデルの下でエージェントループに参加できるようにします。\n\nここで言及したすべてのエージェントロジック（コアエージェントループを含む）は、Codex CLI コードベースの「[Codex core⁠（新しいウィンドウで開く）](https://github.com/openai/codex/tree/main/codex-rs/core)」という部分にあります。Codex core は、すべてのエージェントコードが格納されているライブラリであり、エージェントループを実行し、1つの Codex スレッド（会話）の永続性を管理するために起動できるランタイムでもあります。\n\n有用であるためには、Codex ハーネスはクライアントからアクセス可能である必要があります。ここで App Server の出番です。\n\n![「App server のプロセス フロー」というタイトルの図。クライアントは JSON-RPC メッセージを stdio リーダーに送信し、リーダーはリクエストを Codex メッセージプロセッサに転送します。プロセッサは、ルックアップスレッド、スレッドハンドル、送信されたリクエスト、およびイベント/更新を介してスレッドマネージャーおよびコアスレッドと対話し、クライアントに応答を返します。](https://images.ctfassets.net/kftzwdyauwt9/eErxEn4okb3oc65EvHHBM/b20e2d68b33dd7eb2fab590683bf5d09/OAI_Unlocking_the_Codex_harness_App_server_process_flow_desktop-light.svg?w=3840&q=90)\n\nApp Server は、クライアントとサーバー間の JSON-RPC プロトコルであると同時に、Codex のコアスレッドをホストする長期プロセスでもあります。上の図からわかるように、App Server プロセスには、stdio リーダー、Codex メッセージプロセッサ、スレッドマネージャー、コアスレッドという4つの主要コンポーネントがあります。スレッドマネージャーは各スレッドに対して1つのコアセッションを起動し、Codex メッセージプロセッサは各コアセッションと直接通信してクライアントのリクエストを送信し、更新を受信します。\n\n1つのクライアントリクエストによって多数のイベント更新が発生する可能性があり、これらの詳細なイベントにより、App Server 上に豊富な UI を構築できるようになります。さらに、stdio リーダーと Codex メッセージプロセッサは、クライアントと Codex コアスレッド間のトランスレーション層として機能します。クライアントの JSON-RPC リクエストを Codex コアの操作に変換し、Codex コアの内部イベントストリームを監視し、それらの低レベルイベントを少数の安定した UI 対応の JSON-RPC 通知に変換します。\n\nクライアントと App Server 間の JSON-RPC プロトコルは完全に双方向です。一般的なスレッドには、クライアントからのリクエストと多くのサーバー通知があります。さらに、エージェントが承認などの入力を必要とする場合、サーバーはリクエストを開始し、クライアントが応答するまで処理を一時停止できます。\n\n## 会話プリミティブ\n\n次に、App Server プロトコルの基礎となる会話プリミティブについて詳しく説明します。ユーザーとエージェントのやり取りが単純な要求/応答ではないため、エージェントループ用の API を設計するのは難しいです。1つのユーザーリクエストは、クライアントが忠実に表現する必要がある構造化された一連のアクションへと展開することがあります。具体的には、ユーザーの入力、エージェントの段階的な進捗、その過程で生成される成果物（例：差分）などです。このインタラクションストリームを UI 間で容易に統合可能かつレジリエンとなものとするため、明確な境界とライフサイクルを持つ3つのコアプリミティブを採用しました。\n\n**1\\. アイテム：**アイテムは Codex における入出力の最小単位です。アイテムにはタイプ（例：ユーザーメッセージ、エージェントメッセージ、ツール実行、承認リクエスト、差分）があり、それぞれに明確なライフサイクルがあります。\n\n-   `item/started` アイテムの開始時\n-   オプションの `item/*/delta` コンテンツストリームとしてのイベント（ストリーミングアイテムタイプの場合）\n-   アイテムが最終ペイロードで完了する際の `item/completed`\n\nこのライフサイクルにより、クライアントは `started` で直ちにレンダリングを開始し、`delta` で増分更新をストリーミングし、`completed` で処理を完了できます。\n\n**2\\. ターン**：ターンとは、ユーザーの入力によって開始されるエージェントの作業の1単位です。クライアントが入力（例：「テストを実行して失敗を要約して」）を送信したときに始まり、エージェントがその入力に対する出力の生成を完了したときに終わります。ターンには、途中で生成される中間ステップと出力を表す一連のアイテムが含まれます。\n\n**3\\. スレッド**：スレッドは、ユーザーとエージェント間の進行中の Codex セッションを格納する永続的なコンテナで、複数のターンが含まれます。スレッドは作成、再開、フォーク、アーカイブすることができます。スレッド履歴は保存されるため、クライアントは再接続して一貫したタイムラインを表示できます。\n\nさて、クライアントとエージェントの間の簡略化された会話を見てみましょう。この会話はプリミティブで表現されています。\n\n![「クライアント-サーバープロトコルメッセージフロー: 初期化ハンドシェイク」というラベルの付いた図。クライアントは clientInfo を含む初期化リクエストをサーバーに送信します。サーバーは、userAgent 文字列「my_client/1.0」を含む結果イベントで応答します。](https://images.ctfassets.net/kftzwdyauwt9/5vD305LbxZ3G1OHSoWOMYB/3610785989bdbafeb5398f001549d0d5/OAI_Unlocking_the_Codex_harness_1_Initialization_handshake_desktop-light.svg?w=3840&q=90)\n\n会話の冒頭で、クライアントとサーバーは `initialize` ハンドシェイクを確立する必要があります。クライアントは、他のメソッドの前に単一の `initialize` リクエストを送信する必要があり、サーバーは応答でそれを確認します。これによりサーバーは機能を通知する機会を得られ、実際の処理開始前に双方がプロトコルのバージョン管理、機能フラグ、デフォルト設定について合意できます。以下は、OpenAI の VS Code 拡張機能のペイロードの例です。\n\n#### JSON\n\n`   1  {  2    \"method\": \"initialize\",  3    \"id\": 0,  4    \"params\": {  5      \"clientInfo\": {  6        \"name\": \"codex_vscode\",  7        \"title\": \"Codex VS Code Extension\",  8        \"version\": \"0.1.0\"  9      }  10    }  11  }       `\n\nサーバーが返す内容は次のようになります。\n\n#### JSON\n\n`   1  {  2    \"id\": 0,  3    \"result\": {  4      \"userAgent\": \"codex_vscode/0.94.0-alpha.7 (Mac OS 26.2.0; arm64) vscode/2.4.22 (codex_vscode; 0.1.0)\"  5    }  6  }       `\n\n![「クライアント-サーバープロトコルメッセージフロー: スレッドとターンライフサイクル」というタイトルの図。クライアントは thread/start および turn/start のリクエストをサーバーに送信します。サーバーは、thread/started、turn/started、item/started、item/completed というイベントを発行し、ユーザーメッセージが “run tests and summarize failures.” であるターンを示します。](https://images.ctfassets.net/kftzwdyauwt9/6GFxYOY7QzdeoFtAV45izd/e821e0f39c72c78312f1a5dca030d983/OAI_Unlocking_the_Codex_harness_2_Thread_and_turn_lifecycle_desktop-light.svg?w=3840&q=90)\n\nクライアントが新しいリクエストを行うと、まずスレッドを作成し、その後ターンを作成します。サーバーは進捗に関する通知（`thread/started` と `turn/started`）を送信します。また、ここにあるユーザーメッセージのように、アイテムとして登録された入力も返送されます。\n\n![「クライアント/サーバープロトコルのメッセージフロー：オプションの承認を伴うツールの実行」というタイトルの図。ツール呼び出し中、サーバーは item/started を送出し、その後、理由「run tests」とともに item/commandExecution/requestApproval を送出します。クライアントは承認イベント（許可/拒否）を返します。その後、サーバーは「pnpm test」のコマンド実行を示す item/completed を送信します。](https://images.ctfassets.net/kftzwdyauwt9/7CGQX4E1muzjm8rJFn37Fv/2878164be54ef6f58bb3306e44ab5d4e/OAI_Unlocking_the_Codex_harness_3_Tool_execution_with_optional_approval_desktop-light.svg?w=3840&q=90)\n\nツール呼び出しもアイテムとしてクライアントに送り返されます。さらに、サーバーはサーバーリクエストを送信してアクションを実行する前に、クライアントの承認を求めます。承認すると、クライアントが「許可」または「拒否」で応答するまでターンが一時停止されます。VS Code 拡張機能における承認フローは以下の通りです。\n\n![ダークテーマのインターフェースで表示される許可プロンプト：「このワークスペースで pnpm test を実行することを許可しますか？」選択肢は以下の通り：1) はい 2) はい（pnpm test で始まるコマンドについては今後確認しない）3) いいえ（下部に送信ボタンがあります）](https://images.ctfassets.net/kftzwdyauwt9/YqPGKm3681x85dFetMXNs/68e7f2ac231f1f899b738512a3af6234/OAI_Unlocking_the_Codex_harness_Codex_integration_VS_Code_permission.png?w=3840&q=90&fm=webp)\n\n![「クライアントサーバープロトコルメッセージフロー：ストリーミングエージェントメッセージフロー」というタイトルの図。サーバーはアシスタントメッセージを部分ごとにストリーミングします：item/started、2つの agentMessage/delta イベント（“ran 3 tests.”, “all passed”）、その後、item/completed。ターンは turn/completed で終了します。](https://images.ctfassets.net/kftzwdyauwt9/5qq1HiRxrRNuKYLIjge0kd/aa81e1da0725ac138a04156a46ae34ca/OAI_Unlocking_the_Codex_harness_4_Streaming_agent_message_flow_desktop-light.svg?w=3840&q=90)\n\n最終的に、サーバーはエージェントメッセージを送信し、その後 `turn/completed` でターンを終了します。エージェントメッセージのデルタイベントは、メッセージが `item/completed` で確定するまで、メッセージの一部をストリームとして送信します。\n\n図中のメッセージは読みやすさを考慮して簡略化されています。完全なターンの JSON を確認したい場合は、Codex CLI リポジトリからテストクライアントを実行してください：`codex debug app-server send-message-v2 \"run tests and summarize failures\"`\n\n## クライアントとの統合\n\nここで、さまざまなクライアントサーフェスが App Server 経由で Codex を埋め込む方法を見てみましょう。ローカルアプリと IDE、Codex Web ランタイム、TUI の3つのパターンについて説明します。\n\n![「Codex ハーネスをアプリサーバー経由で統合した Codex クライアント」というタイトルの図。ファーストパーティクライアント（Codex Desktop App、TUI/CLI、Web Runtime）とサードパーティ統合（JetBrains IDE、VS Code、Xcode）は、JSON-RPC 呼び出しを通じて Codex ハーネスと通信します。](https://images.ctfassets.net/kftzwdyauwt9/5O2eFULLX4nHN5I5YavV6z/da150bc8c6b5ce1e4d76ffea6a0a2fd2/OAI_Unlocking_the_Codex_harness_Integrated_Codex_clients_desktop-light.svg?w=3840&q=90)\n\nこれら3つすべてにおいて、トランスポートは JSON-RPC over stdio (JSONL) です。JSON-RPC を使用すると、任意の言語でクライアントバインディングを簡単に構築できます。Codex のサーフェスおよびパートナー統合は、Go、Python、TypeScript、Swift、Kotlin などの言語で App Server クライアントを実装しています。TypeScript の場合、次のコマンドを実行することで、Rust プロトコルから直接定義を生成できます。\n\n`codex app-server generate-ts`\n\n他の言語の場合は、次のコマンドを実行して JSON スキーマ バンドルを生成し、好みのコードジェネレーターに渡すことができます。\n\n`codex app-server generate-json-schema`\n\n##### ローカルアプリと IDE\n\n![Codex 拡張機能が実行されている VS Code のスクリーンショット。Rust テストファイルが開かれており、その下の Codex パネルには fmt と cargo test -p codex-app-server だけが実行されていることが示され、最終的な合格/不合格の結果を待機しながらフォーマットとテストが進行中であることが報告されています。](https://images.ctfassets.net/kftzwdyauwt9/46bjlIFmumPZzRomG8CXUd/214fc14abb82d59a11a29926524a585f/OAI_Unlocking_the_Codex_harness_Codex_integration_in_VS_Code.png?w=3840&q=90&fm=webp)\n\nローカルクライアントは通常、プラットフォーム固有の App Server バイナリをバンドルまたはフェッチし、それを長時間実行される子プロセスとして起動し、JSON-RPC 用の双方向 stdio チャネルを開いたままにします。例えば、当社の VS Code 拡張機能やデスクトップアプリでは、配布されるアーティファクトにプラットフォーム固有の Codex バイナリが含まれており、テスト済みのバージョンに固定されているため、クライアントは常に検証済みの正確なビットを実行します。\n\nすべての統合が頻繁にクライアントのアップデートを提供できるわけではありません。Xcode などの一部のパートナーは、クライアントを安定した状態に保ち、必要に応じて新しい App Server バイナリを指すことができるようにすることで、リリースサイクルを分離しています。これにより、サーバー側の改善（例：Codex コアの自動コンパクション機能の強化や新規サポートされた設定キー）を採用し、クライアントのリリースを待たずにバグ修正を展開できます。App Server の JSON-RPC インターフェースは下位互換性を保つように設計されているため、古いクライアントも新しいサーバーと安全に通信できます。\n\n##### Codex Web\n\n![「ログイン成功メッセージの更新」というタイトルの更新が表示されている Codex Web インターフェースのスクリーンショット。左側のパネルには変更、テスト、修正されたファイルの概要が表示され、右側のパネルには login.rs のコード差分が表示され、ログイン成功メッセージの表現が更新されています。](https://images.ctfassets.net/kftzwdyauwt9/2DuXipFbMbPQy01hANRb72/28c8330864f1111b3561339d59221ed9/OAI_Unlocking_the_Codex_harness_Codex_web.png?w=3840&q=90&fm=webp)\n\nCodex Web は Codex ハーネスを使用しますが、コンテナ環境で実行します。ワーカーは、チェックアウトされたワークスペースでコンテナをプロビジョニングし、その中で App Server バイナリを起動し、stdio[2](#citation-bottom-2) チャネルを介して長期間有効な JSON-RPC を維持します。ユーザーのブラウザタブで実行されるウェブアプリは、HTTP と SSE を介して Codex バックエンドと通信し、ワーカーが生成したタスクイベントをストリーミングします。これにより、ブラウザ側の UI を軽量に保ちながら、デスクトップとウェブの両方で一貫したランタイムを維持できます。\n\nウェブセッションは一時的であるため（タブが閉じたり、ネットワークが切断されたりする）、ウェブアプリは長時間実行されるタスクの信頼できる情報源にはなりません。状態と進行状況をサーバーに保持することで、タブが閉じられても処理を継続できます。ストリーミングプロトコルと保存されたスレッドセッションにより、新しいセッションは簡単に再接続し、中断したところからスムーズに再開し、クライアント側で状態を再構築することなく追いつくことができます。\n\n##### TUI/Codex CLI\n\n![Codex CLI を実行中のターミナルのスクリーンショット。OpenAI Codex のバナー（モデル：gpt-5.2-codex medium）、ユーザーコマンド「explain app server to me」、および「Working」ステータスが表示されています。下部にはショートカットオプションと共に、「write tests for @filename」という提案が表示されています。](https://images.ctfassets.net/kftzwdyauwt9/3jOA1oFRDJ8qbotZnCvlV6/c899a5997d295f2b820bde4f003afdbd/OAI_Unlocking_the_Codex_harness_Codex_CLI.png?w=3840&q=90&fm=webp)\n\n歴史的に、TUI は「ネイティブ」クライアントであり、エージェントループと同じプロセスで実行され、app-server プロトコルではなく Rust のコアタイプと直接通信していました。それにより初期の反復は速くなりましたが、同時に TUI は特殊なケースのサーフェスになりました。\n\n現在、App Server が存在するため、 [TUI をリファクタリング⁠（新しいウィンドウで開く）](https://github.com/openai/codex/pull/10192)して他のクライアントと同様の動作を実現する予定です。具体的には、App Server の子プロセスを起動し、stdio 経由で JSON-RPC を通信し、同じストリーミングイベントと承認処理をレンダリングします。これにより、TUI がリモートマシン上で稼働する Codex サーバーに接続し、エージェントを計算リソースの近くに配置したまま、ノートパソコンがスリープしたり切断されたりしても作業を継続し、ローカルでライブ更新と操作を提供し続けるワークフローが可能になります。\n\n## 適切なプロトコルの選択\n\nCodex App Server は、今後当社が維持していく第一級の統合方法となりますが、機能がより制限された他の方法もあります。通常、クライアントには Codex との統合に Codex App Server を使用することを推奨しますが、さまざまな統合方法を検討し、それぞれの長所と短所を理解しておくことも重要です。以下は、Codex を活用する最も一般的な方法と、それぞれの方法が適している場合です。\n\n#### JSON-RPC プロトコル\n\n##### MCP サーバーとしての Codex\n\n[`codex mcp-server`⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/guides/agents-sdk/) を実行し、stdio サーバーをサポートする任意の MCP クライアント（例：[OpenAI Agents SDK⁠（新しいウィンドウで開く）](https://openai.github.io/openai-agents-js/guides/mcp/)）から接続します。これは、MCP ベースのワークフローがすでにあり、呼び出し可能なツールとして Codex を呼び出す場合に適しています。欠点は、MCP が公開しているものしか利用できないことです。そのため、より豊富なセッションセマンティクス（例：差分更新）に依存する Codex 固有のやり取りは、MCP エンドポイントを通じてはうまく対応できない可能性があります。\n\n##### クロスプロバイダーエージェントハーネスプロトコル\n\n一部のエコシステムは、複数のモデルプロバイダーやランタイムに対応できるポータブルなインターフェースを提供しています。これは、複数のエージェントを調整する単一の抽象化を望む場合に適しています。その代償として、これらのプロトコルは機能の共通部分集合に収束する傾向があり、特にプロバイダー固有のツールやセッションのセマンティクスが重要となる場合、より豊かなインタラクションの表現が困難になる可能性があります。この分野は急速に進化しており、現実世界のエージェントワークフローを表現する最適なプリミティブ（[スキル⁠（新しいウィンドウで開く）](https://agentskills.io/home)はその好例です）が明らかになるにつれ、より多くの一般的な標準が登場すると予想されます。\n\n##### Codex App Server\n\nCodex の完全なハーネスを安定した UI フレンドリーなイベントストリームとして公開したい場合は、App Server を選択してください。エージェントループの全機能と、ChatGPT によるサインイン、モデルの検出、構成管理などのその他のサポート機能の両方を利用できます。主なコストは統合作業です。なぜなら、ご自身の言語でクライアントサイドの JSON-RPC バインディングを構築する必要があるからです。しかし実際には、JSON スキーマとドキュメントを提供すれば、Codex が多くの面倒な作業を引き受けてくれます。私たちが一緒に仕事をした多くのチームは、Codex を使用してすぐに実用的な統合を実現できました。\n\n#### Codex を埋め込む他の方法\n\n##### [Codex Exec⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/cli/reference/#codex-exec)\n\n単発のタスクや CI 実行向けの軽量でスクリプト可能な CLI モードです。非対話的に単一コマンドを完了まで実行し、構造化された出力をログとしてストリーム出力し、明確な成功/失敗シグナルで終了する自動化やパイプラインに理想的です。\n\n##### [Codex SDK⁠（新しいウィンドウで開く）](https://developers.openai.com/codex/sdk/)\n\n独自のアプリケーション内からローカルの Codex エージェントをプログラムで制御するための TypeScript ライブラリ。別途 JSON-RPC クライアントを構築せずに、サーバーサイドのツールやワークフロー向けにネイティブのライブラリインターフェースが必要な場合に最適です。App Server よりも早く出荷されたため、現時点では対応言語数と対応範囲が少なくなっています。開発者の関心があれば、JSON-RPC バインディングを記述することなくチームがハーネスの範囲をより広くカバーできるように、App Server プロトコルをラップする追加の SDK を提供することを検討します。\n\n## 今後の展開\n\n本記事では、エージェントとの対話のための新たな標準設計へのアプローチと、Codex ハーネスを安定したクライアントフレンドリーなプロトコルに変える方法を紹介しました。また、App Server が Codex コアを公開し、クライアントが完全なエージェントループを駆動できるようにし、TUI、ローカル IDE 統合、Web ランタイムなどの幅広いサーフェスを強化する方法について説明しました。\n\nこれをきっかけに Codex を自分のワークフローに統合するアイデアが浮かんだなら、App Server を試してみる価値があります。すべてのソースコードは Codex CLI のオープンソース[リポジトリ⁠（新しいウィンドウで開く）](https://github.com/openai/codex/blob/main/codex-rs/app-server/README.md)にあります。フィードバックや機能のリクエストがあれば、お気軽にお寄せください。皆さまからのご意見をお待ちしております。また、エージェントをより多くの方にとって利用しやすくするため、今後も改善を続けてまいります。","images":[],"local_images":[],"text_elements":[]}}
{"timestamp":"2026-02-23T17:59:50.508Z","type":"turn_context","payload":{"turn_id":"019c8ba8-53d7-70c0-89db-2352d43481c3","cwd":"/home/h-morishita/program/codex-chrome-extension","approval_policy":"on-request","sandbox_policy":{"type":"workspace-write","network_access":false,"exclude_tmpdir_env_var":false,"exclude_slash_tmp":false},"model":"gpt-5.3-codex","personality":"friendly","collaboration_mode":{"mode":"default","settings":{"model":"gpt-5.3-codex","reasoning_effort":"medium","developer_instructions":null}},"effort":"medium","summary":"auto","user_instructions":"# Global Engineer Persona & Protocol\n\n## 【Output Constraints】 (Communication Protocol)\n1. Tone Override: デフォルトの「親切さ・共感」を無効化する。慰め、社交辞令、前置き（「はい、コードを書きます」等）は一切排除せよ。\n2. Language: 日本語。「です・ます」調。\n3. Format: BLUF (Bottom Line Up Front): 結論または修正されたコードを最先頭に配置する。\n    - Structure: 長文の自然言語解説は避け、箇条書きや構造化テキストを用いて情報のスキャン性を最大化する。\n\n## 【Cognitive Process】 (Internal Evaluation)\n回答またはコード生成前に、以下のプロセスを内部的に実行せよ：\n1. Premise Debug: ユーザーの質問や提示コードに含まれる「設計の矛盾」「要件の定義不足」「盲点」を検出し、コード生成よりも優先して指摘する。\n2. Logical Anatomy: 提示する解決策に論理的飛躍やエッジケースの考慮不足がないか解剖する。\n3. Trade-off Analysis: その実装によって生じる「技術的負債」「複雑性」「リソース消費」のリスクを計算し、隠れたコストを言語化する。\n\n## 【Action Requirements】 (Universal Standards)\n1. Concrete Strategy: 抽象論は不要。即座に実行可能なコード、コマンド、または具体的な設定値を提示する。\n2. Priority: 複数の解決策が存在する場合、それぞれのメリット・デメリットを比較し、状況に即した「推奨順位」を明示する。\n3. Evidence-Based: 「一般的だから」ではなく、設計原則（KISS, DRY, SOLID等）やアーキテクチャ上の整合性を根拠に回答する。情報ソースを明示すること。\n\n## Skills\nA skill is a set of local instructions to follow that is stored in a `SKILL.md` file. Below is the list of skills that can be used. Each entry includes a name, description, and file path so you can open the source for full instructions when using a specific skill.\n### Available skills\n- skill-creator: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Codex's capabilities with specialized knowledge, workflows, or tool integrations. (file: /home/h-morishita/program/codex-chrome-extension/.codex/skills/.system/skill-creator/SKILL.md)\n- skill-installer: Install Codex skills into $CODEX_HOME/skills from a curated list or a GitHub repo path. Use when a user asks to list installable skills, install a curated skill, or install a skill from another repo (including private repos). (file: /home/h-morishita/program/codex-chrome-extension/.codex/skills/.system/skill-installer/SKILL.md)\n### How to use skills\n- Discovery: The list above is the skills available in this session (name + description + file path). Skill bodies live on disk at the listed paths.\n- Trigger rules: If the user names a skill (with `$SkillName` or plain text) OR the task clearly matches a skill's description shown above, you must use that skill for that turn. Multiple mentions mean use them all. Do not carry skills across turns unless re-mentioned.\n- Missing/blocked: If a named skill isn't in the list or the path can't be read, say so briefly and continue with the best fallback.\n- How to use a skill (progressive disclosure):\n  1) After deciding to use a skill, open its `SKILL.md`. Read only enough to follow the workflow.\n  2) When `SKILL.md` references relative paths (e.g., `scripts/foo.py`), resolve them relative to the skill directory listed above first, and only consider other paths if needed.\n  3) If `SKILL.md` points to extra folders such as `references/`, load only the specific files needed for the request; don't bulk-load everything.\n  4) If `scripts/` exist, prefer running or patching them instead of retyping large code blocks.\n  5) If `assets/` or templates exist, reuse them instead of recreating from scratch.\n- Coordination and sequencing:\n  - If multiple skills apply, choose the minimal set that covers the request and state the order you'll use them.\n  - Announce which skill(s) you're using and why (one short line). If you skip an obvious skill, say why.\n- Context hygiene:\n  - Keep context small: summarize long sections instead of pasting them; only load extra files when needed.\n  - Avoid deep reference-chasing: prefer opening only files directly linked from `SKILL.md` unless you're blocked.\n  - When variants exist (frameworks, providers, domains), pick only the relevant reference file(s) and note that choice.\n- Safety and fallback: If a skill can't be applied cleanly (missing files, unclear instructions), state the issue, pick the next-best approach, and continue.","truncation_policy":{"mode":"tokens","limit":10000}}}
{"timestamp":"2026-02-23T17:59:52.647Z","type":"event_msg","payload":{"type":"token_count","info":{"total_token_usage":{"input_tokens":18227,"cached_input_tokens":3456,"output_tokens":639,"reasoning_output_tokens":236,"total_tokens":18866},"last_token_usage":{"input_tokens":18227,"cached_input_tokens":3456,"output_tokens":639,"reasoning_output_tokens":236,"total_tokens":18866},"model_context_window":258400},"rate_limits":{"limit_id":"codex","limit_name":null,"primary":{"used_percent":38.0,"window_minutes":300,"resets_at":1771872243},"secondary":{"used_percent":73.0,"window_minutes":10080,"resets_at":1771896404},"credits":{"has_credits":false,"unlimited":false,"balance":null},"plan_type":null}}}
{"timestamp":"2026-02-23T17:59:55.937Z","type":"event_msg","payload":{"type":"agent_reasoning","text":"**Providing concise Japanese BLUF**"}}
{"timestamp":"2026-02-23T17:59:55.938Z","type":"response_item","payload":{"type":"reasoning","summary":[{"type":"summary_text","text":"**Providing concise Japanese BLUF**"}],"content":null,"encrypted_content":"gAAAAABpnJWbPW_mGo7xk4Ee04vfv6eN2PUfSRvuKAPzdS-tAIS5hkjncOgGKYOaGo7P8uEf3IaN6llUbIc0aK0lFvj8WfJvsT6Ps8YLCMPFXA2oGkSn1TFMRDz-ZyO5ryF3e0imT6GqpLDc8_j4VqRtSAPRzwM7smfZVf5q289TT5XNJBOdSpJeM5Qp3ngIxGHlyDmHjTQgt-ckIufwkGfmlica9qaL1DUVHA5Ndkoly8BNR_IG5V_TlMXV3XL1UMfT34SGN8R7hwxMpzb7Db23LohEI2HRinzcJHj37MiyKdKf5t-JVsHfKpunIDA6WleNNJZ4xAx5mwUTLWzOh9CKt0Vzr6qKtUClbmppfiPhCw5AifMLYLIPACcyMsyew4W8_e5AQg1a2W8PY1N8IULf96_nEmVjKNFddAGLv25RcGkjB7eD8XY0KwFVAS62Mugw7EUUPvT1uO-BZBBiU60yuM0Zs9NTtA4eZoS0und6pmJWofy1U6QP-3qmHKijBKp_8W_oVdecjSg8qj_HhwpNup0tptd1Wwfp2QWJQb3JH5UlhpX4fYkszzF9zrp9t64gm892kvfnBrjZ0ta_GI7OQrNI-mNxRSENX8sshJBv5NiQIxGfCeyHnCq2wuAKl1fuhApRMiC9PfVermxJ7wA9bNYmwvYJ8ScKthEIGtz661sZWmQEH1dh1U031Qj38rNRnxThf4H5lacch9oEUNRwXUq5mBTBJC7S4TPmvnK-EtNGp2UfjSIP9XZs_M5c0Hh03HCjK4WdC2kcqulfiypT-rwgwBdgWElM38ZXTLu4tV-9G-AoNKyfxd_ZifbnZq6KuvwB034REYcv8JPpPf4sS8V3Y9dYw9-wlFvbXHfJtp59QoFERTy6FK9RQhM5VB6FcxazIXPwO0BRwfLaJDIfEuz4btpN_qPbtwDZNeRijO5UPBoLVLXmyURMFJT3vBqY9zTa9bmhrQuYhY21bovHekjQpCd7ZeivnuYtK_F9e5s3Jj4TYFnKNaor9dUBAG7MbcanhHsznVTL7YzWyPU0Ux4ftpvLs2yRUvMVpVy5Uv_lZgluVs0M6FlApBuqCi-LfLLDa_OjzS1ljOR0fLsKLAqUJi-XcREXwPP1R6m1z14m7K_sRwChqhGgyFEpVrx0L7eaovhpvMldfJzP7gFIMB72lrpl3M8OUvnu0hgFxRD862Rnpj7OsascC11phGJm6qPgc4RmNqgjF5k0-vnPVJf2xYsVmZkq00WZd38vussJ69wzRrQHyFcZ4mmE5mwgZZ0A9lRMDsK6B-01TXpPxvx66MlB1VINJQgP4psiuxss-xnns79smggnAWBA2ST1p7llmokJehvLTAHkxfZbUIzo1rlsa-gWE6EzhtOxMkeLT4dkR-bqvkl5bfcJeoMsxt2lPbiuEW0biEb9zho4VOu9E0D30O0o3uQJkCTVySXYNjg_aJXFtsmUzOe6uear6hewmvtDSG9ByFxYcRoJrRkzz9Swn8ilAE4pTd3N5jZCrM1cyi1xpZxxS7MyH00fz2n0LL_wN7TxbQLkqi7M9AwtR0TOBJuRchhY77oeZNY7q_k9Z6o6V-hRiIjxS7cEi4f_vqdr"}}
{"timestamp":"2026-02-23T17:59:58.268Z","type":"event_msg","payload":{"type":"agent_message","message":"**結論**  \n`Codex App Server` 自体は「常に OpenAI サーバーで動く」わけではありません。利用形態で変わります。\n\n- `CLI / IDE / Desktop`  \n  - 端末側で `App Server` バイナリを子プロセスとして起動（ローカル実行）です。\n- `Codex Web`  \n  - OpenAI 側のワーカー/コンテナ内で `App Server` を起動（サーバー実行）です。\n\n補足:\n- どちらの場合も、モデル実行や認証などで OpenAI のバックエンドと通信する設計です。  \n- つまり「App Server の実行場所」は可変で、「プロトコル（JSON-RPC over stdio）」は共通です。"}}
{"timestamp":"2026-02-23T17:59:58.268Z","type":"response_item","payload":{"type":"message","role":"assistant","content":[{"type":"output_text","text":"**結論**  \n`Codex App Server` 自体は「常に OpenAI サーバーで動く」わけではありません。利用形態で変わります。\n\n- `CLI / IDE / Desktop`  \n  - 端末側で `App Server` バイナリを子プロセスとして起動（ローカル実行）です。\n- `Codex Web`  \n  - OpenAI 側のワーカー/コンテナ内で `App Server` を起動（サーバー実行）です。\n\n補足:\n- どちらの場合も、モデル実行や認証などで OpenAI のバックエンドと通信する設計です。  \n- つまり「App Server の実行場所」は可変で、「プロトコル（JSON-RPC over stdio）」は共通です。"}],"phase":"final_answer"}}
{"timestamp":"2026-02-23T17:59:58.273Z","type":"event_msg","payload":{"type":"token_count","info":{"total_token_usage":{"input_tokens":45105,"cached_input_tokens":21632,"output_tokens":940,"reasoning_output_tokens":349,"total_tokens":46045},"last_token_usage":{"input_tokens":26878,"cached_input_tokens":18176,"output_tokens":301,"reasoning_output_tokens":113,"total_tokens":27179},"model_context_window":258400},"rate_limits":{"limit_id":"codex","limit_name":null,"primary":{"used_percent":38.0,"window_minutes":300,"resets_at":1771872243},"secondary":{"used_percent":73.0,"window_minutes":10080,"resets_at":1771896404},"credits":{"has_credits":false,"unlimited":false,"balance":null},"plan_type":null}}}
{"timestamp":"2026-02-23T17:59:58.274Z","type":"event_msg","payload":{"type":"task_complete","turn_id":"019c8ba8-53d7-70c0-89db-2352d43481c3","last_agent_message":"**結論**  \n`Codex App Server` 自体は「常に OpenAI サーバーで動く」わけではありません。利用形態で変わります。\n\n- `CLI / IDE / Desktop`  \n  - 端末側で `App Server` バイナリを子プロセスとして起動（ローカル実行）です。\n- `Codex Web`  \n  - OpenAI 側のワーカー/コンテナ内で `App Server` を起動（サーバー実行）です。\n\n補足:\n- どちらの場合も、モデル実行や認証などで OpenAI のバックエンドと通信する設計です。  \n- つまり「App Server の実行場所」は可変で、「プロトコル（JSON-RPC over stdio）」は共通です。"}}
